//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_80
.address_size 64

	// .globl	triton_
.extern .shared .align 16 .b8 global_smem[];
.global .align 1 .b8 _$_str[11] = {95, 95, 67, 85, 68, 65, 95, 70, 84, 90};

.visible .entry triton_(
	.param .u64 triton__param_0,
	.param .u64 triton__param_1,
	.param .u64 triton__param_2,
	.param .u64 triton__param_3,
	.param .u32 triton__param_4
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<147>;
	.reg .b16 	%rs<75>;
	.reg .b32 	%r<1502>;
	.reg .f32 	%f<1678>;
	.reg .b64 	%rd<101>;
	.loc	1 19 0
$L__func_begin0:
	.loc	1 19 0

	ld.param.u64 	%rd17, [triton__param_3];
	ld.param.u64 	%rd16, [triton__param_2];
	ld.param.u64 	%rd15, [triton__param_0];
	ld.param.u64 	%rd42, [triton__param_1];
$L__tmp0:
	.loc	1 21 24
	// begin inline asm
	mov.u32 %r69, %ctaid.x;
	// end inline asm
	.loc	1 23 17
	shr.s32 	%r124, %r69, 31;
	shr.u32 	%r125, %r124, 30;
	add.s32 	%r126, %r69, %r125;
	shr.s32 	%r127, %r126, 2;
	.loc	1 23 28
	shr.s32 	%r128, %r126, 31;
	shr.u32 	%r129, %r128, 22;
	add.s32 	%r130, %r127, %r129;
	and.b32  	%r131, %r130, -1024;
	sub.s32 	%r132, %r127, %r131;
	.loc	1 24 28
	shr.u32 	%r133, %r128, 27;
	add.s32 	%r134, %r127, %r133;
	and.b32  	%r135, %r134, -32;
	sub.s32 	%r136, %r127, %r135;
	and.b32  	%r137, %r126, 33554428;
	sub.s32 	%r138, %r69, %r137;
	.loc	1 26 20
	shl.b32 	%r1, %r138, 7;
	.loc	1 27 33
	mov.u32 	%r2, %tid.x;
	shr.u32 	%r139, %r2, 3;
	bfe.u32 	%r140, %r2, 3, 3;
	and.b32  	%r141, %r2, 64;
	shr.u32 	%r142, %r141, 3;
	or.b32  	%r55, %r140, %r142;
	or.b32  	%r143, %r55, 16;
	or.b32  	%r144, %r55, 32;
	or.b32  	%r145, %r55, 48;
	or.b32  	%r146, %r55, 64;
	or.b32  	%r147, %r55, 80;
	or.b32  	%r148, %r55, 96;
	or.b32  	%r149, %r55, 112;
	bfe.u32 	%r150, %r2, 2, 3;
	shr.u32 	%r151, %r2, 1;
	and.b32  	%r152, %r151, 16;
	shr.u32 	%r153, %r141, 1;
	.loc	1 27 20
	or.b32  	%r154, %r1, %r55;
	or.b32  	%r155, %r1, %r143;
	or.b32  	%r156, %r1, %r144;
	or.b32  	%r157, %r1, %r145;
	or.b32  	%r158, %r1, %r146;
	or.b32  	%r159, %r1, %r147;
	or.b32  	%r160, %r1, %r148;
	or.b32  	%r161, %r1, %r149;
	.loc	1 28 22
	shl.b32 	%r162, %r2, 3;
	and.b32  	%r163, %r162, 56;
	.loc	1 35 25
	shl.b32 	%r164, %r2, 1;
	and.b32  	%r3, %r164, 6;
	.loc	1 48 58
	shl.b32 	%r165, %r154, 6;
	shl.b32 	%r166, %r155, 6;
	shl.b32 	%r167, %r156, 6;
	shl.b32 	%r168, %r157, 6;
	shl.b32 	%r169, %r158, 6;
	shl.b32 	%r170, %r159, 6;
	shl.b32 	%r171, %r160, 6;
	shl.b32 	%r172, %r161, 6;
	.loc	1 48 79
	shl.b32 	%r4, %r132, 15;
	.loc	1 48 54
	or.b32  	%r173, %r4, %r163;
	.loc	1 48 73
	add.s32 	%r174, %r173, %r165;
	add.s32 	%r175, %r173, %r166;
	add.s32 	%r176, %r173, %r167;
	add.s32 	%r177, %r173, %r168;
	add.s32 	%r178, %r173, %r169;
	add.s32 	%r179, %r173, %r170;
	add.s32 	%r180, %r173, %r171;
	add.s32 	%r181, %r173, %r172;
	.loc	1 48 38
	mul.wide.s32 	%rd43, %r174, 2;
	add.s64 	%rd55, %rd42, %rd43;
	mul.wide.s32 	%rd44, %r175, 2;
	add.s64 	%rd56, %rd42, %rd44;
	mul.wide.s32 	%rd45, %r176, 2;
	add.s64 	%rd57, %rd42, %rd45;
	mul.wide.s32 	%rd46, %r177, 2;
	add.s64 	%rd58, %rd42, %rd46;
	mul.wide.s32 	%rd47, %r178, 2;
	add.s64 	%rd59, %rd42, %rd47;
	mul.wide.s32 	%rd48, %r179, 2;
	add.s64 	%rd60, %rd42, %rd48;
	mul.wide.s32 	%rd49, %r180, 2;
	add.s64 	%rd61, %rd42, %rd49;
	mul.wide.s32 	%rd50, %r181, 2;
	add.s64 	%rd62, %rd42, %rd50;
	.loc	1 59 20
	add.s32 	%r182, %r136, 1;
	.loc	1 60 25
	cvt.rn.f32.s32 	%f252, %r182;
	.loc	1 62 24
	mul.f32 	%f253, %f252, 0f41000000;
	.loc	1 65 17
	fma.rn.f32 	%f1, %f253, 0fBD000000, 0f00000000;
	.loc	1 73 26
	cvt.u16.u32 	%rs1, %r132;
	shr.s16 	%rs2, %rs1, 15;
	shr.u16 	%rs3, %rs2, 11;
	add.s16 	%rs4, %rs1, %rs3;
	and.b16  	%rs5, %rs4, -32;
	sub.s16 	%rs6, %rs1, %rs5;
	.loc	1 73 21
	add.s16 	%rs7, %rs6, 1;
	.loc	1 74 25
	cvt.rn.f32.s16 	%f254, %rs7;
	.loc	1 75 24
	mul.f32 	%f255, %f254, 0f41000000;
	.loc	1 77 17
	fma.rn.f32 	%f2, %f255, 0fBD000000, 0f00000000;
	.loc	1 48 84
	shl.b32 	%r183, %r55, 6;
	xor.b32  	%r184, %r139, %r2;
	shl.b32 	%r185, %r184, 3;
	and.b32  	%r186, %r185, 56;
	or.b32  	%r5, %r183, %r186;
	shl.b32 	%r187, %r5, 1;
	mov.u32 	%r121, global_smem;
	add.s32 	%r70, %r121, %r187;
	shl.b32 	%r188, %r143, 6;
	or.b32  	%r6, %r188, %r186;
	shl.b32 	%r189, %r6, 1;
	add.s32 	%r72, %r121, %r189;
	shl.b32 	%r190, %r144, 6;
	or.b32  	%r7, %r190, %r186;
	shl.b32 	%r191, %r7, 1;
	add.s32 	%r74, %r121, %r191;
	shl.b32 	%r192, %r145, 6;
	or.b32  	%r8, %r192, %r186;
	shl.b32 	%r193, %r8, 1;
	add.s32 	%r76, %r121, %r193;
	shl.b32 	%r194, %r146, 6;
	or.b32  	%r9, %r194, %r186;
	shl.b32 	%r195, %r9, 1;
	add.s32 	%r78, %r121, %r195;
	shl.b32 	%r196, %r147, 6;
	or.b32  	%r10, %r196, %r186;
	shl.b32 	%r197, %r10, 1;
	add.s32 	%r80, %r121, %r197;
	shl.b32 	%r198, %r148, 6;
	or.b32  	%r11, %r198, %r186;
	shl.b32 	%r199, %r11, 1;
	add.s32 	%r82, %r121, %r199;
	shl.b32 	%r200, %r149, 6;
	or.b32  	%r12, %r200, %r186;
	shl.b32 	%r201, %r12, 1;
	add.s32 	%r84, %r121, %r201;
	mov.b32 	%r71, 16;
	mov.pred 	%p131, -1;
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r70 + 0 ], [ %rd55 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r72 + 0 ], [ %rd56 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r74 + 0 ], [ %rd57 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r76 + 0 ], [ %rd58 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r78 + 0 ], [ %rd59 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r80 + 0 ], [ %rd60 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r82 + 0 ], [ %rd61 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r84 + 0 ], [ %rd62 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 49 54
	or.b32  	%r202, %r183, %r163;
	or.b32  	%r203, %r188, %r163;
	.loc	1 49 73
	or.b32  	%r204, %r202, %r4;
	or.b32  	%r205, %r203, %r4;
	.loc	1 49 38
	mul.wide.s32 	%rd51, %r204, 2;
	add.s64 	%rd26, %rd16, %rd51;
	mul.wide.s32 	%rd52, %r205, 2;
	add.s64 	%rd27, %rd16, %rd52;
	.loc	1 49 84
	add.s32 	%r120, %r121, 32768;
	add.s32 	%r86, %r120, %r187;
	add.s32 	%r88, %r120, %r189;
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r86 + 0 ], [ %rd26 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r88 + 0 ], [ %rd27 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 55 35
	add.s64 	%rd28, %rd17, %rd51;
	add.s64 	%rd29, %rd17, %rd52;
	.loc	1 55 81
	add.s32 	%r119, %r121, 40960;
	add.s32 	%r90, %r119, %r187;
	add.s32 	%r92, %r119, %r189;
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r90 + 0 ], [ %rd28 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r92 + 0 ], [ %rd29 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 48 84
	bar.sync 	0;
	add.s32 	%r206, %r121, 16384;
	add.s32 	%r94, %r206, %r187;
	add.s32 	%r96, %r206, %r189;
	add.s32 	%r98, %r206, %r191;
	add.s32 	%r100, %r206, %r193;
	add.s32 	%r102, %r206, %r195;
	add.s32 	%r104, %r206, %r197;
	add.s32 	%r106, %r206, %r199;
	add.s32 	%r108, %r206, %r201;
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r94 + 0 ], [ %rd55 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r96 + 0 ], [ %rd56 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r98 + 0 ], [ %rd57 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r100 + 0 ], [ %rd58 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r102 + 0 ], [ %rd59 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r104 + 0 ], [ %rd60 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r106 + 0 ], [ %rd61 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r108 + 0 ], [ %rd62 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 49 73
	or.b32  	%r207, %r204, 2048;
	or.b32  	%r208, %r204, 3072;
	.loc	1 49 38
	mul.wide.s32 	%rd53, %r207, 2;
	add.s64 	%rd38, %rd16, %rd53;
	mul.wide.s32 	%rd54, %r208, 2;
	add.s64 	%rd39, %rd16, %rd54;
	.loc	1 49 84
	add.s32 	%r209, %r121, 36864;
	add.s32 	%r110, %r209, %r187;
	add.s32 	%r112, %r209, %r189;
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r110 + 0 ], [ %rd38 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r112 + 0 ], [ %rd39 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 55 35
	add.s64 	%rd40, %rd17, %rd53;
	add.s64 	%rd41, %rd17, %rd54;
	.loc	1 55 81
	add.s32 	%r210, %r121, 45056;
	add.s32 	%r114, %r210, %r187;
	add.s32 	%r116, %r210, %r189;
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r114 + 0 ], [ %rd40 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r116 + 0 ], [ %rd41 + 0 ], 0x10, %r71;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 48 84
	// begin inline asm
	cp.async.wait_group 0x3;
	// end inline asm
	bar.sync 	0;
	bfe.u32 	%r211, %r2, 5, 2;
	and.b32  	%r212, %r2, 7;
	bfe.u32 	%r213, %r2, 3, 1;
	bfe.u32 	%r214, %r2, 4, 1;
	shl.b32 	%r215, %r211, 1;
	or.b32  	%r216, %r215, %r213;
	or.b32  	%r217, %r214, 2;
	or.b32  	%r218, %r214, 4;
	or.b32  	%r219, %r214, 6;
	or.b32  	%r220, %r213, 2;
	or.b32  	%r221, %r213, 4;
	or.b32  	%r222, %r213, 6;
	shl.b32 	%r223, %r211, 4;
	or.b32  	%r13, %r223, %r150;
	mul.lo.s32 	%r224, %r13, 34;
	add.s32 	%r225, %r224, %r3;
	shl.b32 	%r226, %r225, 2;
	add.s32 	%r227, %r121, 49152;
	add.s32 	%r14, %r227, %r226;
	or.b32  	%r15, %r3, 8;
	add.s32 	%r228, %r224, %r15;
	shl.b32 	%r229, %r228, 2;
	add.s32 	%r16, %r227, %r229;
	or.b32  	%r17, %r3, 16;
	add.s32 	%r230, %r224, %r17;
	shl.b32 	%r231, %r230, 2;
	add.s32 	%r18, %r227, %r231;
	or.b32  	%r19, %r3, 24;
	add.s32 	%r232, %r224, %r19;
	shl.b32 	%r233, %r232, 2;
	add.s32 	%r20, %r227, %r233;
	or.b32  	%r234, %r215, %r214;
	and.b32  	%r235, %r164, 30;
	mul.lo.s32 	%r21, %r234, 68;
	add.s32 	%r236, %r21, %r235;
	shl.b32 	%r237, %r236, 2;
	add.s32 	%r22, %r227, %r237;
	and.b32  	%r238, %r139, 6;
	or.b32  	%r239, %r238, %r142;
	bfe.u32 	%r240, %r139, 1, 2;
	shl.b32 	%r241, %r239, 5;
	bfe.u32 	%r242, %r2, 2, 2;
	xor.b32  	%r243, %r240, %r242;
	shl.b32 	%r244, %r243, 3;
	or.b32  	%r245, %r244, %r241;
	or.b32  	%r246, %r245, %r3;
	shl.b32 	%r247, %r246, 2;
	add.s32 	%r23, %r227, %r247;
	or.b32  	%r248, %r247, 128;
	add.s32 	%r24, %r227, %r248;
	or.b32  	%r249, %r247, 2048;
	add.s32 	%r25, %r227, %r249;
	or.b32  	%r250, %r247, 2176;
	add.s32 	%r26, %r227, %r250;
	or.b32  	%r251, %r247, 4096;
	add.s32 	%r27, %r227, %r251;
	or.b32  	%r252, %r247, 4224;
	add.s32 	%r28, %r227, %r252;
	or.b32  	%r253, %r247, 6144;
	add.s32 	%r29, %r227, %r253;
	or.b32  	%r254, %r247, 6272;
	add.s32 	%r30, %r227, %r254;
	or.b32  	%r255, %r247, 8192;
	add.s32 	%r31, %r227, %r255;
	or.b32  	%r256, %r247, 8320;
	add.s32 	%r32, %r227, %r256;
	or.b32  	%r257, %r247, 10240;
	add.s32 	%r33, %r227, %r257;
	or.b32  	%r258, %r247, 10368;
	add.s32 	%r34, %r227, %r258;
	or.b32  	%r259, %r247, 12288;
	add.s32 	%r35, %r227, %r259;
	or.b32  	%r260, %r247, 12416;
	add.s32 	%r36, %r227, %r260;
	or.b32  	%r261, %r247, 14336;
	add.s32 	%r37, %r227, %r261;
	or.b32  	%r262, %r247, 14464;
	add.s32 	%r38, %r227, %r262;
	and.b32  	%r263, %r2, 24;
	or.b32  	%r264, %r263, %r3;
	shl.b32 	%r265, %r211, 9;
	shl.b32 	%r266, %r150, 5;
	or.b32  	%r267, %r265, %r266;
	or.b32  	%r268, %r267, %r264;
	shl.b32 	%r269, %r268, 2;
	add.s32 	%r39, %r227, %r269;
	xor.b32  	%r270, %r268, 8;
	shl.b32 	%r271, %r270, 2;
	add.s32 	%r40, %r227, %r271;
	xor.b32  	%r272, %r268, 16;
	shl.b32 	%r273, %r272, 2;
	add.s32 	%r41, %r227, %r273;
	xor.b32  	%r274, %r268, 24;
	shl.b32 	%r275, %r274, 2;
	add.s32 	%r42, %r227, %r275;
	xor.b32  	%r276, %r214, %r212;
	shl.b32 	%r277, %r216, 9;
	shl.b32 	%r278, %r212, 6;
	or.b32  	%r279, %r277, %r278;
	shl.b32 	%r280, %r276, 3;
	or.b32  	%r43, %r280, %r279;
	xor.b32  	%r281, %r217, %r212;
	shl.b32 	%r282, %r281, 3;
	or.b32  	%r44, %r282, %r279;
	xor.b32  	%r283, %r218, %r212;
	shl.b32 	%r284, %r283, 3;
	or.b32  	%r45, %r284, %r279;
	xor.b32  	%r285, %r219, %r212;
	shl.b32 	%r286, %r285, 3;
	or.b32  	%r46, %r286, %r279;
	xor.b32  	%r287, %r213, %r212;
	shl.b32 	%r288, %r214, 9;
	or.b32  	%r289, %r288, %r278;
	shl.b32 	%r290, %r287, 3;
	or.b32  	%r47, %r290, %r289;
	xor.b32  	%r291, %r220, %r212;
	shl.b32 	%r292, %r291, 3;
	or.b32  	%r48, %r292, %r289;
	xor.b32  	%r293, %r221, %r212;
	shl.b32 	%r294, %r293, 3;
	or.b32  	%r49, %r294, %r289;
	xor.b32  	%r295, %r222, %r212;
	shl.b32 	%r296, %r295, 3;
	or.b32  	%r50, %r296, %r289;
	shl.b32 	%r297, %r2, 6;
	and.b32  	%r298, %r297, 960;
	or.b32  	%r51, %r280, %r298;
	or.b32  	%r52, %r282, %r298;
	or.b32  	%r53, %r284, %r298;
	or.b32  	%r54, %r286, %r298;
	.loc	1 36 33
	cvt.u16.u32 	%rs8, %r2;
	shr.u16 	%rs9, %rs8, 6;
	and.b16  	%rs10, %rs9, 1;
	mul.wide.u16 	%r299, %rs10, 512;
	or.b32  	%r300, %r4, %r299;
	shl.b32 	%r301, %r140, 6;
	or.b32  	%r302, %r300, %r301;
	or.b32  	%r303, %r302, %r163;
	or.b32  	%r304, %r303, 5120;
	mul.wide.s32 	%rd100, %r304, 2;
	or.b32  	%r305, %r303, 4096;
	mul.wide.s32 	%rd99, %r305, 2;
	shl.b32 	%r306, %r127, 9;
	or.b32  	%r307, %r306, %r3;
	sub.s32 	%r308, %r307, %r150;
	sub.s32 	%r309, %r308, %r152;
	sub.s32 	%r310, %r309, %r153;
	shl.b32 	%r311, %r69, 7;
	sub.s32 	%r56, %r310, %r311;
	mov.f32 	%f250, 0f00000000;
	mov.f32 	%f1638, 0fFF800000;
	mov.b32 	%r1501, 1;
	mov.b32 	%r1500, 0;
	mov.b32 	%r1496, -32;
	shl.b32 	%r1096, %r43, 1;
	shl.b32 	%r1097, %r44, 1;
	shl.b32 	%r1098, %r45, 1;
	shl.b32 	%r1099, %r46, 1;
	shl.b32 	%r1100, %r47, 1;
	shl.b32 	%r1101, %r48, 1;
	shl.b32 	%r1102, %r49, 1;
	shl.b32 	%r1103, %r50, 1;
	ex2.approx.ftz.f32 	%f1168, %f1;
	ex2.approx.ftz.f32 	%f1321, %f2;
	shl.b32 	%r1141, %r51, 1;
	shl.b32 	%r1142, %r52, 1;
	shl.b32 	%r1143, %r53, 1;
	shl.b32 	%r1144, %r54, 1;
	mov.u32 	%r1497, %r119;
	mov.u32 	%r1498, %r120;
	mov.u32 	%r1499, %r121;
	mov.f32 	%f712, %f250;
	mov.f32 	%f713, %f250;
	mov.f32 	%f714, %f250;
	mov.f32 	%f715, %f250;
	mov.f32 	%f720, %f250;
	mov.f32 	%f721, %f250;
	mov.f32 	%f722, %f250;
	mov.f32 	%f723, %f250;
	mov.f32 	%f728, %f250;
	mov.f32 	%f729, %f250;
	mov.f32 	%f730, %f250;
	mov.f32 	%f731, %f250;
	mov.f32 	%f736, %f250;
	mov.f32 	%f737, %f250;
	mov.f32 	%f738, %f250;
	mov.f32 	%f739, %f250;
	mov.f32 	%f744, %f250;
	mov.f32 	%f745, %f250;
	mov.f32 	%f746, %f250;
	mov.f32 	%f747, %f250;
	mov.f32 	%f752, %f250;
	mov.f32 	%f753, %f250;
	mov.f32 	%f754, %f250;
	mov.f32 	%f755, %f250;
	mov.f32 	%f760, %f250;
	mov.f32 	%f761, %f250;
	mov.f32 	%f762, %f250;
	mov.f32 	%f763, %f250;
	mov.f32 	%f768, %f250;
	mov.f32 	%f769, %f250;
	mov.f32 	%f770, %f250;
	mov.f32 	%f771, %f250;
	mov.f32 	%f776, %f250;
	mov.f32 	%f777, %f250;
	mov.f32 	%f778, %f250;
	mov.f32 	%f779, %f250;
	mov.f32 	%f784, %f250;
	mov.f32 	%f785, %f250;
	mov.f32 	%f786, %f250;
	mov.f32 	%f787, %f250;
	mov.f32 	%f792, %f250;
	mov.f32 	%f793, %f250;
	mov.f32 	%f794, %f250;
	mov.f32 	%f795, %f250;
	mov.f32 	%f800, %f250;
	mov.f32 	%f801, %f250;
	mov.f32 	%f802, %f250;
	mov.f32 	%f803, %f250;
	mov.f32 	%f808, %f250;
	mov.f32 	%f809, %f250;
	mov.f32 	%f810, %f250;
	mov.f32 	%f811, %f250;
	mov.f32 	%f816, %f250;
	mov.f32 	%f817, %f250;
	mov.f32 	%f818, %f250;
	mov.f32 	%f819, %f250;
	mov.f32 	%f824, %f250;
	mov.f32 	%f825, %f250;
	mov.f32 	%f826, %f250;
	mov.f32 	%f827, %f250;
	mov.f32 	%f832, %f250;
	mov.f32 	%f833, %f250;
	mov.f32 	%f834, %f250;
	mov.f32 	%f835, %f250;
	mov.f32 	%f1639, %f1638;
	mov.f32 	%f1640, %f1638;
	mov.f32 	%f1641, %f1638;
	mov.f32 	%f1642, %f1638;
	mov.f32 	%f1643, %f1638;
	mov.f32 	%f1644, %f1638;
	mov.f32 	%f1645, %f1638;
	mov.f32 	%f1646, %f250;
	mov.f32 	%f1647, %f250;
	mov.f32 	%f1648, %f250;
	mov.f32 	%f1649, %f250;
	mov.f32 	%f1650, %f250;
	mov.f32 	%f1651, %f250;
	mov.f32 	%f1652, %f250;
	mov.f32 	%f1653, %f250;
	mov.f32 	%f1654, %f250;
	mov.f32 	%f1655, %f250;
	mov.f32 	%f1656, %f250;
	mov.f32 	%f1657, %f250;
	mov.f32 	%f1658, %f250;
	mov.f32 	%f1659, %f250;
	mov.f32 	%f1660, %f250;
	mov.f32 	%f1661, %f250;
	mov.f32 	%f1662, %f250;
	mov.f32 	%f1663, %f250;
	mov.f32 	%f1664, %f250;
	mov.f32 	%f1665, %f250;
	mov.f32 	%f1666, %f250;
	mov.f32 	%f1667, %f250;
	mov.f32 	%f1668, %f250;
	mov.f32 	%f1669, %f250;
	mov.f32 	%f1670, %f250;
	mov.f32 	%f1671, %f250;
	mov.f32 	%f1672, %f250;
	mov.f32 	%f1673, %f250;
	mov.f32 	%f1674, %f250;
	mov.f32 	%f1675, %f250;
	mov.f32 	%f1676, %f250;
	mov.f32 	%f1677, %f250;
$L__BB0_1:
	add.s32 	%r63, %r1496, 32;
	setp.lt.u32 	%p37, %r63, 448;
	.loc	1 48 84
	add.s32 	%r316, %r1499, %r1096;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r392, %r393, %r394, %r395 }, [ %r316 + 0 ];
	// end inline asm
	add.s32 	%r321, %r1499, %r1097;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r440, %r441, %r442, %r443 }, [ %r321 + 0 ];
	// end inline asm
	add.s32 	%r326, %r1499, %r1098;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r488, %r489, %r490, %r491 }, [ %r326 + 0 ];
	// end inline asm
	add.s32 	%r331, %r1499, %r1099;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r536, %r537, %r538, %r539 }, [ %r331 + 0 ];
	// end inline asm
	add.s32 	%r336, %r316, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r416, %r417, %r418, %r419 }, [ %r336 + 0 ];
	// end inline asm
	add.s32 	%r341, %r321, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r464, %r465, %r466, %r467 }, [ %r341 + 0 ];
	// end inline asm
	add.s32 	%r346, %r326, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r512, %r513, %r514, %r515 }, [ %r346 + 0 ];
	// end inline asm
	add.s32 	%r351, %r331, 8192;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r560, %r561, %r562, %r563 }, [ %r351 + 0 ];
	// end inline asm
	.loc	1 49 84
	add.s32 	%r356, %r1498, %r1100;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r396, %r397, %r402, %r403 }, [ %r356 + 0 ];
	// end inline asm
	add.s32 	%r361, %r1498, %r1101;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r444, %r445, %r450, %r451 }, [ %r361 + 0 ];
	// end inline asm
	add.s32 	%r366, %r1498, %r1102;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r492, %r493, %r498, %r499 }, [ %r366 + 0 ];
	// end inline asm
	add.s32 	%r371, %r1498, %r1103;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r540, %r541, %r546, %r547 }, [ %r371 + 0 ];
	// end inline asm
	add.s32 	%r376, %r356, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r408, %r409, %r414, %r415 }, [ %r376 + 0 ];
	// end inline asm
	add.s32 	%r381, %r361, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r456, %r457, %r462, %r463 }, [ %r381 + 0 ];
	// end inline asm
	add.s32 	%r386, %r366, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r504, %r505, %r510, %r511 }, [ %r386 + 0 ];
	// end inline asm
	add.s32 	%r391, %r371, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r552, %r553, %r558, %r559 }, [ %r391 + 0 ];
	// end inline asm
	.loc	1 52 32
	mov.f32 	%f320, %f250;
	mov.f32 	%f321, %f250;
	mov.f32 	%f322, %f250;
	mov.f32 	%f323, %f250;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f320, %f321, %f322, %f323 }, { %r392, %r393, %r394, %r395 }, { %r396, %r397 }, { %f320, %f321, %f322, %f323 };
	// end inline asm
	mov.f32 	%f328, %f250;
	mov.f32 	%f329, %f250;
	mov.f32 	%f330, %f250;
	mov.f32 	%f331, %f250;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f328, %f329, %f330, %f331 }, { %r392, %r393, %r394, %r395 }, { %r402, %r403 }, { %f328, %f329, %f330, %f331 };
	// end inline asm
	mov.f32 	%f336, %f250;
	mov.f32 	%f337, %f250;
	mov.f32 	%f338, %f250;
	mov.f32 	%f339, %f250;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f336, %f337, %f338, %f339 }, { %r392, %r393, %r394, %r395 }, { %r408, %r409 }, { %f336, %f337, %f338, %f339 };
	// end inline asm
	mov.f32 	%f344, %f250;
	mov.f32 	%f345, %f250;
	mov.f32 	%f346, %f250;
	mov.f32 	%f347, %f250;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f344, %f345, %f346, %f347 }, { %r392, %r393, %r394, %r395 }, { %r414, %r415 }, { %f344, %f345, %f346, %f347 };
	// end inline asm
	mov.f32 	%f352, %f250;
	mov.f32 	%f353, %f250;
	mov.f32 	%f354, %f250;
	mov.f32 	%f355, %f250;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f352, %f353, %f354, %f355 }, { %r416, %r417, %r418, %r419 }, { %r396, %r397 }, { %f352, %f353, %f354, %f355 };
	// end inline asm
	mov.f32 	%f360, %f250;
	mov.f32 	%f361, %f250;
	mov.f32 	%f362, %f250;
	mov.f32 	%f363, %f250;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f360, %f361, %f362, %f363 }, { %r416, %r417, %r418, %r419 }, { %r402, %r403 }, { %f360, %f361, %f362, %f363 };
	// end inline asm
	mov.f32 	%f368, %f250;
	mov.f32 	%f369, %f250;
	mov.f32 	%f370, %f250;
	mov.f32 	%f371, %f250;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f368, %f369, %f370, %f371 }, { %r416, %r417, %r418, %r419 }, { %r408, %r409 }, { %f368, %f369, %f370, %f371 };
	// end inline asm
	mov.f32 	%f376, %f250;
	mov.f32 	%f377, %f250;
	mov.f32 	%f378, %f250;
	mov.f32 	%f379, %f250;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f376, %f377, %f378, %f379 }, { %r416, %r417, %r418, %r419 }, { %r414, %r415 }, { %f376, %f377, %f378, %f379 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f320, %f321, %f322, %f323 }, { %r440, %r441, %r442, %r443 }, { %r444, %r445 }, { %f320, %f321, %f322, %f323 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f328, %f329, %f330, %f331 }, { %r440, %r441, %r442, %r443 }, { %r450, %r451 }, { %f328, %f329, %f330, %f331 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f336, %f337, %f338, %f339 }, { %r440, %r441, %r442, %r443 }, { %r456, %r457 }, { %f336, %f337, %f338, %f339 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f344, %f345, %f346, %f347 }, { %r440, %r441, %r442, %r443 }, { %r462, %r463 }, { %f344, %f345, %f346, %f347 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f352, %f353, %f354, %f355 }, { %r464, %r465, %r466, %r467 }, { %r444, %r445 }, { %f352, %f353, %f354, %f355 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f360, %f361, %f362, %f363 }, { %r464, %r465, %r466, %r467 }, { %r450, %r451 }, { %f360, %f361, %f362, %f363 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f368, %f369, %f370, %f371 }, { %r464, %r465, %r466, %r467 }, { %r456, %r457 }, { %f368, %f369, %f370, %f371 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f376, %f377, %f378, %f379 }, { %r464, %r465, %r466, %r467 }, { %r462, %r463 }, { %f376, %f377, %f378, %f379 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f320, %f321, %f322, %f323 }, { %r488, %r489, %r490, %r491 }, { %r492, %r493 }, { %f320, %f321, %f322, %f323 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f328, %f329, %f330, %f331 }, { %r488, %r489, %r490, %r491 }, { %r498, %r499 }, { %f328, %f329, %f330, %f331 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f336, %f337, %f338, %f339 }, { %r488, %r489, %r490, %r491 }, { %r504, %r505 }, { %f336, %f337, %f338, %f339 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f344, %f345, %f346, %f347 }, { %r488, %r489, %r490, %r491 }, { %r510, %r511 }, { %f344, %f345, %f346, %f347 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f352, %f353, %f354, %f355 }, { %r512, %r513, %r514, %r515 }, { %r492, %r493 }, { %f352, %f353, %f354, %f355 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f360, %f361, %f362, %f363 }, { %r512, %r513, %r514, %r515 }, { %r498, %r499 }, { %f360, %f361, %f362, %f363 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f368, %f369, %f370, %f371 }, { %r512, %r513, %r514, %r515 }, { %r504, %r505 }, { %f368, %f369, %f370, %f371 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f376, %f377, %f378, %f379 }, { %r512, %r513, %r514, %r515 }, { %r510, %r511 }, { %f376, %f377, %f378, %f379 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f320, %f321, %f322, %f323 }, { %r536, %r537, %r538, %r539 }, { %r540, %r541 }, { %f320, %f321, %f322, %f323 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f328, %f329, %f330, %f331 }, { %r536, %r537, %r538, %r539 }, { %r546, %r547 }, { %f328, %f329, %f330, %f331 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f336, %f337, %f338, %f339 }, { %r536, %r537, %r538, %r539 }, { %r552, %r553 }, { %f336, %f337, %f338, %f339 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f344, %f345, %f346, %f347 }, { %r536, %r537, %r538, %r539 }, { %r558, %r559 }, { %f344, %f345, %f346, %f347 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f352, %f353, %f354, %f355 }, { %r560, %r561, %r562, %r563 }, { %r540, %r541 }, { %f352, %f353, %f354, %f355 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f360, %f361, %f362, %f363 }, { %r560, %r561, %r562, %r563 }, { %r546, %r547 }, { %f360, %f361, %f362, %f363 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f368, %f369, %f370, %f371 }, { %r560, %r561, %r562, %r563 }, { %r552, %r553 }, { %f368, %f369, %f370, %f371 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f376, %f377, %f378, %f379 }, { %r560, %r561, %r562, %r563 }, { %r558, %r559 }, { %f376, %f377, %f378, %f379 };
	// end inline asm
	.loc	1 57 22
	mul.f32 	%f1160, %f322, 0f3E000000;
	mul.f32 	%f1161, %f323, 0f3E000000;
	mul.f32 	%f1162, %f344, 0f3E000000;
	mul.f32 	%f1163, %f345, 0f3E000000;
	mul.f32 	%f1164, %f354, 0f3E000000;
	mul.f32 	%f1165, %f355, 0f3E000000;
	mul.f32 	%f1166, %f376, 0f3E000000;
	mul.f32 	%f1167, %f377, 0f3E000000;
	.loc	1 67 32
	add.s32 	%r1104, %r56, %r1496;
	add.s32 	%r1105, %r1104, 32;
	add.s32 	%r1106, %r1104, 33;
	add.s32 	%r1107, %r1104, 24;
	add.s32 	%r1108, %r1104, 25;
	add.s32 	%r1109, %r1104, 40;
	add.s32 	%r1110, %r1104, 41;
	add.s32 	%r1111, %r1104, 48;
	add.s32 	%r1112, %r1104, 49;
	add.s32 	%r1113, %r1104, 56;
	add.s32 	%r1114, %r1104, 57;
	add.s32 	%r1115, %r1104, -32;
	add.s32 	%r1116, %r1104, -31;
	add.s32 	%r1117, %r1104, -40;
	add.s32 	%r1118, %r1104, -39;
	add.s32 	%r1119, %r1104, -24;
	add.s32 	%r1120, %r1104, -23;
	add.s32 	%r1121, %r1104, -16;
	add.s32 	%r1122, %r1104, -15;
	add.s32 	%r1123, %r1104, -8;
	add.s32 	%r1124, %r1104, -7;
	.loc	1 68 25
	cvt.rn.f32.s32 	%f1169, %r1105;
	cvt.rn.f32.s32 	%f1170, %r1106;
	cvt.rn.f32.s32 	%f1171, %r1107;
	cvt.rn.f32.s32 	%f1172, %r1108;
	cvt.rn.f32.s32 	%f1173, %r1109;
	cvt.rn.f32.s32 	%f1174, %r1110;
	cvt.rn.f32.s32 	%f1175, %r1111;
	cvt.rn.f32.s32 	%f1176, %r1112;
	cvt.rn.f32.s32 	%f1177, %r1113;
	cvt.rn.f32.s32 	%f1178, %r1114;
	cvt.rn.f32.s32 	%f1179, %r1115;
	cvt.rn.f32.s32 	%f1180, %r1116;
	cvt.rn.f32.s32 	%f1181, %r1117;
	cvt.rn.f32.s32 	%f1182, %r1118;
	cvt.rn.f32.s32 	%f1183, %r1119;
	cvt.rn.f32.s32 	%f1184, %r1120;
	cvt.rn.f32.s32 	%f1185, %r1121;
	cvt.rn.f32.s32 	%f1186, %r1122;
	cvt.rn.f32.s32 	%f1187, %r1123;
	cvt.rn.f32.s32 	%f1188, %r1124;
	.loc	1 69 24
	mul.f32 	%f1189, %f1168, %f1169;
	mul.f32 	%f1190, %f1168, %f1170;
	mul.f32 	%f1191, %f1168, %f1173;
	mul.f32 	%f1192, %f1168, %f1174;
	mul.f32 	%f1193, %f1168, %f1175;
	mul.f32 	%f1194, %f1168, %f1176;
	mul.f32 	%f1195, %f1168, %f1179;
	mul.f32 	%f1196, %f1168, %f1180;
	mul.f32 	%f1197, %f1168, %f1183;
	mul.f32 	%f1198, %f1168, %f1184;
	mul.f32 	%f1199, %f1168, %f1185;
	mul.f32 	%f1200, %f1168, %f1186;
	.loc	1 70 23
	fma.rn.f32 	%f1201, %f320, 0f3E000000, %f1189;
	fma.rn.f32 	%f1202, %f321, 0f3E000000, %f1190;
	fma.rn.f32 	%f1203, %f1168, %f1171, %f1160;
	fma.rn.f32 	%f1204, %f1168, %f1172, %f1161;
	fma.rn.f32 	%f1205, %f328, 0f3E000000, %f1191;
	fma.rn.f32 	%f1206, %f329, 0f3E000000, %f1192;
	fma.rn.f32 	%f1207, %f330, 0f3E000000, %f1189;
	fma.rn.f32 	%f1208, %f331, 0f3E000000, %f1190;
	fma.rn.f32 	%f1209, %f336, 0f3E000000, %f1193;
	fma.rn.f32 	%f1210, %f337, 0f3E000000, %f1194;
	fma.rn.f32 	%f1211, %f338, 0f3E000000, %f1191;
	fma.rn.f32 	%f1212, %f339, 0f3E000000, %f1192;
	fma.rn.f32 	%f1213, %f1168, %f1177, %f1162;
	fma.rn.f32 	%f1214, %f1168, %f1178, %f1163;
	fma.rn.f32 	%f1215, %f346, 0f3E000000, %f1193;
	fma.rn.f32 	%f1216, %f347, 0f3E000000, %f1194;
	fma.rn.f32 	%f1217, %f352, 0f3E000000, %f1195;
	fma.rn.f32 	%f1218, %f353, 0f3E000000, %f1196;
	fma.rn.f32 	%f1219, %f1168, %f1181, %f1164;
	fma.rn.f32 	%f1220, %f1168, %f1182, %f1165;
	fma.rn.f32 	%f1221, %f360, 0f3E000000, %f1197;
	fma.rn.f32 	%f1222, %f361, 0f3E000000, %f1198;
	fma.rn.f32 	%f1223, %f362, 0f3E000000, %f1195;
	fma.rn.f32 	%f1224, %f363, 0f3E000000, %f1196;
	fma.rn.f32 	%f1225, %f368, 0f3E000000, %f1199;
	fma.rn.f32 	%f1226, %f369, 0f3E000000, %f1200;
	fma.rn.f32 	%f1227, %f370, 0f3E000000, %f1197;
	fma.rn.f32 	%f1228, %f371, 0f3E000000, %f1198;
	fma.rn.f32 	%f1229, %f1168, %f1187, %f1166;
	fma.rn.f32 	%f1230, %f1168, %f1188, %f1167;
	fma.rn.f32 	%f1231, %f378, 0f3E000000, %f1199;
	fma.rn.f32 	%f1232, %f379, 0f3E000000, %f1200;
$L__tmp1:
	.loc	2 82 15
	setp.gt.f32 	%p38, %f1201, %f1202;
	.loc	2 84 21
	setp.nan.f32 	%p39, %f1201, %f1201;
	.loc	2 85 29
	selp.f32 	%f1233, %f1201, %f1202, %p39;
	selp.f32 	%f1234, %f1201, %f1233, %p38;
	.loc	2 82 15
	setp.gt.f32 	%p40, %f1203, %f1204;
	.loc	2 84 21
	setp.nan.f32 	%p41, %f1203, %f1203;
	.loc	2 85 29
	selp.f32 	%f1235, %f1203, %f1204, %p41;
	selp.f32 	%f1236, %f1203, %f1235, %p40;
	.loc	2 82 15
	setp.gt.f32 	%p42, %f1234, %f1205;
	.loc	2 84 21
	setp.nan.f32 	%p43, %f1234, %f1234;
	.loc	2 85 29
	selp.f32 	%f1237, %f1234, %f1205, %p43;
	selp.f32 	%f1238, %f1234, %f1237, %p42;
	.loc	2 82 15
	setp.gt.f32 	%p44, %f1238, %f1206;
	.loc	2 84 21
	setp.nan.f32 	%p45, %f1238, %f1238;
	.loc	2 85 29
	selp.f32 	%f1239, %f1238, %f1206, %p45;
	selp.f32 	%f1240, %f1238, %f1239, %p44;
	.loc	2 82 15
	setp.gt.f32 	%p46, %f1236, %f1207;
	.loc	2 84 21
	setp.nan.f32 	%p47, %f1236, %f1236;
	.loc	2 85 29
	selp.f32 	%f1241, %f1236, %f1207, %p47;
	selp.f32 	%f1242, %f1236, %f1241, %p46;
	.loc	2 82 15
	setp.gt.f32 	%p48, %f1242, %f1208;
	.loc	2 84 21
	setp.nan.f32 	%p49, %f1242, %f1242;
	.loc	2 85 29
	selp.f32 	%f1243, %f1242, %f1208, %p49;
	selp.f32 	%f1244, %f1242, %f1243, %p48;
	.loc	2 82 15
	setp.gt.f32 	%p50, %f1240, %f1209;
	.loc	2 84 21
	setp.nan.f32 	%p51, %f1240, %f1240;
	.loc	2 85 29
	selp.f32 	%f1245, %f1240, %f1209, %p51;
	selp.f32 	%f1246, %f1240, %f1245, %p50;
	.loc	2 82 15
	setp.gt.f32 	%p52, %f1246, %f1210;
	.loc	2 84 21
	setp.nan.f32 	%p53, %f1246, %f1246;
	.loc	2 85 29
	selp.f32 	%f1247, %f1246, %f1210, %p53;
	selp.f32 	%f1248, %f1246, %f1247, %p52;
	.loc	2 82 15
	setp.gt.f32 	%p54, %f1244, %f1211;
	.loc	2 84 21
	setp.nan.f32 	%p55, %f1244, %f1244;
	.loc	2 85 29
	selp.f32 	%f1249, %f1244, %f1211, %p55;
	selp.f32 	%f1250, %f1244, %f1249, %p54;
	.loc	2 82 15
	setp.gt.f32 	%p56, %f1250, %f1212;
	.loc	2 84 21
	setp.nan.f32 	%p57, %f1250, %f1250;
	.loc	2 85 29
	selp.f32 	%f1251, %f1250, %f1212, %p57;
	selp.f32 	%f1252, %f1250, %f1251, %p56;
	.loc	2 82 15
	setp.gt.f32 	%p58, %f1248, %f1213;
	.loc	2 84 21
	setp.nan.f32 	%p59, %f1248, %f1248;
	.loc	2 85 29
	selp.f32 	%f1253, %f1248, %f1213, %p59;
	selp.f32 	%f1254, %f1248, %f1253, %p58;
	.loc	2 82 15
	setp.gt.f32 	%p60, %f1254, %f1214;
	.loc	2 84 21
	setp.nan.f32 	%p61, %f1254, %f1254;
	.loc	2 85 29
	selp.f32 	%f1255, %f1254, %f1214, %p61;
	selp.f32 	%f1256, %f1254, %f1255, %p60;
	.loc	2 82 15
	setp.gt.f32 	%p62, %f1252, %f1215;
	.loc	2 84 21
	setp.nan.f32 	%p63, %f1252, %f1252;
	.loc	2 85 29
	selp.f32 	%f1257, %f1252, %f1215, %p63;
	selp.f32 	%f1258, %f1252, %f1257, %p62;
	.loc	2 82 15
	setp.gt.f32 	%p64, %f1258, %f1216;
	.loc	2 84 21
	setp.nan.f32 	%p65, %f1258, %f1258;
	.loc	2 85 29
	selp.f32 	%f1259, %f1258, %f1216, %p65;
	selp.f32 	%f1260, %f1258, %f1259, %p64;
	.loc	2 82 15
	setp.gt.f32 	%p66, %f1217, %f1218;
	.loc	2 84 21
	setp.nan.f32 	%p67, %f1217, %f1217;
	.loc	2 85 29
	selp.f32 	%f1261, %f1217, %f1218, %p67;
	selp.f32 	%f1262, %f1217, %f1261, %p66;
	.loc	2 82 15
	setp.gt.f32 	%p68, %f1219, %f1220;
	.loc	2 84 21
	setp.nan.f32 	%p69, %f1219, %f1219;
	.loc	2 85 29
	selp.f32 	%f1263, %f1219, %f1220, %p69;
	selp.f32 	%f1264, %f1219, %f1263, %p68;
	.loc	2 82 15
	setp.gt.f32 	%p70, %f1262, %f1221;
	.loc	2 84 21
	setp.nan.f32 	%p71, %f1262, %f1262;
	.loc	2 85 29
	selp.f32 	%f1265, %f1262, %f1221, %p71;
	selp.f32 	%f1266, %f1262, %f1265, %p70;
	.loc	2 82 15
	setp.gt.f32 	%p72, %f1266, %f1222;
	.loc	2 84 21
	setp.nan.f32 	%p73, %f1266, %f1266;
	.loc	2 85 29
	selp.f32 	%f1267, %f1266, %f1222, %p73;
	selp.f32 	%f1268, %f1266, %f1267, %p72;
	.loc	2 82 15
	setp.gt.f32 	%p74, %f1264, %f1223;
	.loc	2 84 21
	setp.nan.f32 	%p75, %f1264, %f1264;
	.loc	2 85 29
	selp.f32 	%f1269, %f1264, %f1223, %p75;
	selp.f32 	%f1270, %f1264, %f1269, %p74;
	.loc	2 82 15
	setp.gt.f32 	%p76, %f1270, %f1224;
	.loc	2 84 21
	setp.nan.f32 	%p77, %f1270, %f1270;
	.loc	2 85 29
	selp.f32 	%f1271, %f1270, %f1224, %p77;
	selp.f32 	%f1272, %f1270, %f1271, %p76;
	.loc	2 82 15
	setp.gt.f32 	%p78, %f1268, %f1225;
	.loc	2 84 21
	setp.nan.f32 	%p79, %f1268, %f1268;
	.loc	2 85 29
	selp.f32 	%f1273, %f1268, %f1225, %p79;
	selp.f32 	%f1274, %f1268, %f1273, %p78;
	.loc	2 82 15
	setp.gt.f32 	%p80, %f1274, %f1226;
	.loc	2 84 21
	setp.nan.f32 	%p81, %f1274, %f1274;
	.loc	2 85 29
	selp.f32 	%f1275, %f1274, %f1226, %p81;
	selp.f32 	%f1276, %f1274, %f1275, %p80;
	.loc	2 82 15
	setp.gt.f32 	%p82, %f1272, %f1227;
	.loc	2 84 21
	setp.nan.f32 	%p83, %f1272, %f1272;
	.loc	2 85 29
	selp.f32 	%f1277, %f1272, %f1227, %p83;
	selp.f32 	%f1278, %f1272, %f1277, %p82;
	.loc	2 82 15
	setp.gt.f32 	%p84, %f1278, %f1228;
	.loc	2 84 21
	setp.nan.f32 	%p85, %f1278, %f1278;
	.loc	2 85 29
	selp.f32 	%f1279, %f1278, %f1228, %p85;
	selp.f32 	%f1280, %f1278, %f1279, %p84;
	.loc	2 82 15
	setp.gt.f32 	%p86, %f1276, %f1229;
	.loc	2 84 21
	setp.nan.f32 	%p87, %f1276, %f1276;
	.loc	2 85 29
	selp.f32 	%f1281, %f1276, %f1229, %p87;
	selp.f32 	%f1282, %f1276, %f1281, %p86;
	.loc	2 82 15
	setp.gt.f32 	%p88, %f1282, %f1230;
	.loc	2 84 21
	setp.nan.f32 	%p89, %f1282, %f1282;
	.loc	2 85 29
	selp.f32 	%f1283, %f1282, %f1230, %p89;
	selp.f32 	%f1284, %f1282, %f1283, %p88;
	.loc	2 82 15
	setp.gt.f32 	%p90, %f1280, %f1231;
	.loc	2 84 21
	setp.nan.f32 	%p91, %f1280, %f1280;
	.loc	2 85 29
	selp.f32 	%f1285, %f1280, %f1231, %p91;
	selp.f32 	%f1286, %f1280, %f1285, %p90;
	.loc	2 82 15
	setp.gt.f32 	%p92, %f1286, %f1232;
	.loc	2 84 21
	setp.nan.f32 	%p93, %f1286, %f1286;
	.loc	2 85 29
	selp.f32 	%f1287, %f1286, %f1232, %p93;
	selp.f32 	%f1288, %f1286, %f1287, %p92;
	.loc	2 95 29
	mov.b32 	%r1125, %f1256;
	shfl.sync.bfly.b32	%r1126, %r1125, 2, 31, -1;
	mov.b32 	%f1289, %r1126;
	.loc	2 82 15
	setp.gt.f32 	%p94, %f1256, %f1289;
	.loc	2 84 21
	setp.nan.f32 	%p95, %f1256, %f1256;
	.loc	2 95 29
	mov.b32 	%r1127, %f1260;
	.loc	2 84 21
	setp.nan.f32 	%p96, %f1260, %f1260;
	.loc	2 95 29
	mov.b32 	%r1128, %f1284;
	.loc	2 84 21
	setp.nan.f32 	%p97, %f1284, %f1284;
	.loc	2 95 29
	mov.b32 	%r1129, %f1288;
	.loc	2 84 21
	setp.nan.f32 	%p98, %f1288, %f1288;
$L__tmp2:
	.loc	2 84 21
	setp.nan.f32 	%p99, %f1645, %f1645;
	setp.nan.f32 	%p100, %f1644, %f1644;
	setp.nan.f32 	%p101, %f1643, %f1643;
	setp.nan.f32 	%p102, %f1642, %f1642;
	setp.nan.f32 	%p103, %f1638, %f1638;
	setp.nan.f32 	%p104, %f1639, %f1639;
	setp.nan.f32 	%p105, %f1640, %f1640;
	setp.nan.f32 	%p106, %f1641, %f1641;
$L__tmp3:
	.loc	2 85 29
	selp.f32 	%f1290, %f1256, %f1289, %p95;
	selp.f32 	%f1291, %f1256, %f1290, %p94;
	.loc	2 95 29
	mov.b32 	%r1130, %f1291;
	shfl.sync.bfly.b32	%r1131, %r1130, 1, 31, -1;
	shfl.sync.bfly.b32	%r1132, %r1127, 2, 31, -1;
	mov.b32 	%f1292, %r1132;
	.loc	2 82 15
	setp.gt.f32 	%p107, %f1260, %f1292;
	.loc	2 85 29
	selp.f32 	%f1293, %f1260, %f1292, %p96;
	selp.f32 	%f1294, %f1260, %f1293, %p107;
	.loc	2 95 29
	mov.b32 	%r1133, %f1294;
	shfl.sync.bfly.b32	%r1134, %r1133, 1, 31, -1;
	shfl.sync.bfly.b32	%r1135, %r1128, 2, 31, -1;
	mov.b32 	%f1295, %r1135;
	.loc	2 82 15
	setp.gt.f32 	%p108, %f1284, %f1295;
	.loc	2 85 29
	selp.f32 	%f1296, %f1284, %f1295, %p97;
	selp.f32 	%f1297, %f1284, %f1296, %p108;
	.loc	2 95 29
	mov.b32 	%r1136, %f1297;
	shfl.sync.bfly.b32	%r1137, %r1136, 1, 31, -1;
	shfl.sync.bfly.b32	%r1138, %r1129, 2, 31, -1;
	mov.b32 	%f1298, %r1138;
	.loc	2 82 15
	setp.gt.f32 	%p109, %f1288, %f1298;
	.loc	2 85 29
	selp.f32 	%f1299, %f1288, %f1298, %p98;
	selp.f32 	%f1300, %f1288, %f1299, %p109;
	.loc	2 95 29
	mov.b32 	%r1139, %f1300;
	shfl.sync.bfly.b32	%r1140, %r1139, 1, 31, -1;
	mov.b32 	%f1301, %r1140;
	mov.b32 	%f1302, %r1137;
	mov.b32 	%f1303, %r1134;
	mov.b32 	%f1304, %r1131;
	.loc	2 82 15
	setp.gt.f32 	%p110, %f1291, %f1304;
	setp.gt.f32 	%p111, %f1294, %f1303;
	setp.gt.f32 	%p112, %f1297, %f1302;
	setp.gt.f32 	%p113, %f1300, %f1301;
	.loc	2 84 21
	setp.nan.f32 	%p114, %f1291, %f1291;
	setp.nan.f32 	%p115, %f1294, %f1294;
	setp.nan.f32 	%p116, %f1297, %f1297;
	setp.nan.f32 	%p117, %f1300, %f1300;
	.loc	2 85 29
	selp.f32 	%f1305, %f1300, %f1301, %p117;
	selp.f32 	%f1306, %f1300, %f1305, %p113;
	selp.f32 	%f1307, %f1297, %f1302, %p116;
	selp.f32 	%f1308, %f1297, %f1307, %p112;
	selp.f32 	%f1309, %f1294, %f1303, %p115;
	selp.f32 	%f1310, %f1294, %f1309, %p111;
	selp.f32 	%f1311, %f1291, %f1304, %p114;
	selp.f32 	%f1312, %f1291, %f1311, %p110;
$L__tmp4:
	.loc	2 82 15
	setp.gt.f32 	%p118, %f1645, %f1312;
	setp.gt.f32 	%p119, %f1644, %f1310;
	setp.gt.f32 	%p120, %f1643, %f1308;
	setp.gt.f32 	%p121, %f1642, %f1306;
	setp.gt.f32 	%p122, %f1638, %f1306;
	setp.gt.f32 	%p123, %f1639, %f1308;
	setp.gt.f32 	%p124, %f1640, %f1310;
	setp.gt.f32 	%p125, %f1641, %f1312;
	.loc	2 85 29
	selp.f32 	%f1313, %f1641, %f1312, %p125;
	selp.f32 	%f1641, %f1641, %f1313, %p106;
	selp.f32 	%f1314, %f1640, %f1310, %p124;
	selp.f32 	%f1640, %f1640, %f1314, %p105;
	selp.f32 	%f1315, %f1639, %f1308, %p123;
	selp.f32 	%f1639, %f1639, %f1315, %p104;
	selp.f32 	%f1316, %f1638, %f1306, %p122;
	selp.f32 	%f1638, %f1638, %f1316, %p103;
	selp.f32 	%f1317, %f1642, %f1306, %p121;
	selp.f32 	%f111, %f1642, %f1317, %p102;
	selp.f32 	%f1318, %f1643, %f1308, %p120;
	selp.f32 	%f112, %f1643, %f1318, %p101;
	selp.f32 	%f1319, %f1644, %f1310, %p119;
	selp.f32 	%f113, %f1644, %f1319, %p100;
	selp.f32 	%f1320, %f1645, %f1312, %p118;
	selp.f32 	%f114, %f1645, %f1320, %p99;
$L__tmp5:
	.loc	1 79 24
	mul.f32 	%f1322, %f1321, %f1169;
	mul.f32 	%f1323, %f1321, %f1170;
	mul.f32 	%f1324, %f1321, %f1173;
	mul.f32 	%f1325, %f1321, %f1174;
	mul.f32 	%f1326, %f1321, %f1175;
	mul.f32 	%f1327, %f1321, %f1176;
	mul.f32 	%f1328, %f1321, %f1179;
	mul.f32 	%f1329, %f1321, %f1180;
	mul.f32 	%f1330, %f1321, %f1183;
	mul.f32 	%f1331, %f1321, %f1184;
	mul.f32 	%f1332, %f1321, %f1185;
	mul.f32 	%f1333, %f1321, %f1186;
	.loc	1 80 23
	fma.rn.f32 	%f1334, %f320, 0f3E000000, %f1322;
	fma.rn.f32 	%f1335, %f321, 0f3E000000, %f1323;
	fma.rn.f32 	%f1336, %f1321, %f1171, %f1160;
	fma.rn.f32 	%f1337, %f1321, %f1172, %f1161;
	fma.rn.f32 	%f1338, %f328, 0f3E000000, %f1324;
	fma.rn.f32 	%f1339, %f329, 0f3E000000, %f1325;
	fma.rn.f32 	%f1340, %f330, 0f3E000000, %f1322;
	fma.rn.f32 	%f1341, %f331, 0f3E000000, %f1323;
	fma.rn.f32 	%f1342, %f336, 0f3E000000, %f1326;
	fma.rn.f32 	%f1343, %f337, 0f3E000000, %f1327;
	fma.rn.f32 	%f1344, %f338, 0f3E000000, %f1324;
	fma.rn.f32 	%f1345, %f339, 0f3E000000, %f1325;
	fma.rn.f32 	%f1346, %f1321, %f1177, %f1162;
	fma.rn.f32 	%f1347, %f1321, %f1178, %f1163;
	fma.rn.f32 	%f1348, %f346, 0f3E000000, %f1326;
	fma.rn.f32 	%f1349, %f347, 0f3E000000, %f1327;
	fma.rn.f32 	%f1350, %f352, 0f3E000000, %f1328;
	fma.rn.f32 	%f1351, %f353, 0f3E000000, %f1329;
	fma.rn.f32 	%f1352, %f1321, %f1181, %f1164;
	fma.rn.f32 	%f1353, %f1321, %f1182, %f1165;
	fma.rn.f32 	%f1354, %f360, 0f3E000000, %f1330;
	fma.rn.f32 	%f1355, %f361, 0f3E000000, %f1331;
	fma.rn.f32 	%f1356, %f362, 0f3E000000, %f1328;
	fma.rn.f32 	%f1357, %f363, 0f3E000000, %f1329;
	fma.rn.f32 	%f1358, %f368, 0f3E000000, %f1332;
	fma.rn.f32 	%f1359, %f369, 0f3E000000, %f1333;
	fma.rn.f32 	%f1360, %f370, 0f3E000000, %f1330;
	fma.rn.f32 	%f1361, %f371, 0f3E000000, %f1331;
	fma.rn.f32 	%f1362, %f1321, %f1187, %f1166;
	fma.rn.f32 	%f1363, %f1321, %f1188, %f1167;
	fma.rn.f32 	%f1364, %f378, 0f3E000000, %f1332;
	fma.rn.f32 	%f1365, %f379, 0f3E000000, %f1333;
	.loc	1 81 24
	sub.f32 	%f1366, %f1334, %f114;
	sub.f32 	%f1367, %f1335, %f114;
	sub.f32 	%f1368, %f1336, %f113;
	sub.f32 	%f1369, %f1337, %f113;
	sub.f32 	%f1370, %f1338, %f114;
	sub.f32 	%f1371, %f1339, %f114;
	sub.f32 	%f1372, %f1340, %f113;
	sub.f32 	%f1373, %f1341, %f113;
	sub.f32 	%f1374, %f1342, %f114;
	sub.f32 	%f1375, %f1343, %f114;
	sub.f32 	%f1376, %f1344, %f113;
	sub.f32 	%f1377, %f1345, %f113;
	sub.f32 	%f1378, %f1346, %f114;
	sub.f32 	%f1379, %f1347, %f114;
	sub.f32 	%f1380, %f1348, %f113;
	sub.f32 	%f1381, %f1349, %f113;
	sub.f32 	%f1382, %f1350, %f112;
	sub.f32 	%f1383, %f1351, %f112;
	sub.f32 	%f1384, %f1352, %f111;
	sub.f32 	%f1385, %f1353, %f111;
	sub.f32 	%f1386, %f1354, %f112;
	sub.f32 	%f1387, %f1355, %f112;
	sub.f32 	%f1388, %f1356, %f111;
	sub.f32 	%f1389, %f1357, %f111;
	sub.f32 	%f1390, %f1358, %f112;
	sub.f32 	%f1391, %f1359, %f112;
	sub.f32 	%f1392, %f1360, %f111;
	sub.f32 	%f1393, %f1361, %f111;
	sub.f32 	%f1394, %f1362, %f112;
	sub.f32 	%f1395, %f1363, %f112;
	sub.f32 	%f1396, %f1364, %f111;
	sub.f32 	%f1397, %f1365, %f111;
	.loc	1 82 28
	mul.f32 	%f513, %f1366, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f512, %f513;
	// end inline asm
	mul.f32 	%f515, %f1367, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f514, %f515;
	// end inline asm
	mul.f32 	%f517, %f1368, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f516, %f517;
	// end inline asm
	mul.f32 	%f519, %f1369, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f518, %f519;
	// end inline asm
	mul.f32 	%f521, %f1370, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f520, %f521;
	// end inline asm
	mul.f32 	%f523, %f1371, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f522, %f523;
	// end inline asm
	mul.f32 	%f525, %f1372, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f524, %f525;
	// end inline asm
	mul.f32 	%f527, %f1373, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f526, %f527;
	// end inline asm
	mul.f32 	%f529, %f1374, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f528, %f529;
	// end inline asm
	mul.f32 	%f531, %f1375, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f530, %f531;
	// end inline asm
	mul.f32 	%f533, %f1376, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f532, %f533;
	// end inline asm
	mul.f32 	%f535, %f1377, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f534, %f535;
	// end inline asm
	mul.f32 	%f537, %f1378, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f536, %f537;
	// end inline asm
	mul.f32 	%f539, %f1379, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f538, %f539;
	// end inline asm
	mul.f32 	%f541, %f1380, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f540, %f541;
	// end inline asm
	mul.f32 	%f543, %f1381, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f542, %f543;
	// end inline asm
	mul.f32 	%f545, %f1382, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f544, %f545;
	// end inline asm
	mul.f32 	%f547, %f1383, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f546, %f547;
	// end inline asm
	mul.f32 	%f549, %f1384, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f548, %f549;
	// end inline asm
	mul.f32 	%f551, %f1385, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f550, %f551;
	// end inline asm
	mul.f32 	%f553, %f1386, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f552, %f553;
	// end inline asm
	mul.f32 	%f555, %f1387, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f554, %f555;
	// end inline asm
	mul.f32 	%f557, %f1388, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f556, %f557;
	// end inline asm
	mul.f32 	%f559, %f1389, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f558, %f559;
	// end inline asm
	mul.f32 	%f561, %f1390, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f560, %f561;
	// end inline asm
	mul.f32 	%f563, %f1391, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f562, %f563;
	// end inline asm
	mul.f32 	%f565, %f1392, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f564, %f565;
	// end inline asm
	mul.f32 	%f567, %f1393, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f566, %f567;
	// end inline asm
	mul.f32 	%f569, %f1394, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f568, %f569;
	// end inline asm
	mul.f32 	%f571, %f1395, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f570, %f571;
	// end inline asm
	mul.f32 	%f573, %f1396, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f572, %f573;
	// end inline asm
	mul.f32 	%f575, %f1397, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f574, %f575;
	// end inline asm
	.loc	1 87 24
	sub.f32 	%f1398, %f1642, %f111;
	sub.f32 	%f1399, %f1643, %f112;
	sub.f32 	%f1400, %f1644, %f113;
	sub.f32 	%f1401, %f1645, %f114;
	.loc	1 88 28
	mul.f32 	%f577, %f1401, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f576, %f577;
	// end inline asm
	mul.f32 	%f579, %f1400, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f578, %f579;
	// end inline asm
	mul.f32 	%f581, %f1399, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f580, %f581;
	// end inline asm
	mul.f32 	%f583, %f1398, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f582, %f583;
	// end inline asm
	.loc	1 89 24
	mul.f32 	%f712, %f712, %f576;
	mul.f32 	%f713, %f713, %f576;
	mul.f32 	%f714, %f714, %f578;
	mul.f32 	%f715, %f715, %f578;
	mul.f32 	%f720, %f720, %f576;
	mul.f32 	%f721, %f721, %f576;
	mul.f32 	%f722, %f722, %f578;
	mul.f32 	%f723, %f723, %f578;
	mul.f32 	%f728, %f728, %f576;
	mul.f32 	%f729, %f729, %f576;
	mul.f32 	%f730, %f730, %f578;
	mul.f32 	%f731, %f731, %f578;
	mul.f32 	%f736, %f736, %f576;
	mul.f32 	%f737, %f737, %f576;
	mul.f32 	%f738, %f738, %f578;
	mul.f32 	%f739, %f739, %f578;
	mul.f32 	%f744, %f744, %f576;
	mul.f32 	%f745, %f745, %f576;
	mul.f32 	%f746, %f746, %f578;
	mul.f32 	%f747, %f747, %f578;
	mul.f32 	%f752, %f752, %f576;
	mul.f32 	%f753, %f753, %f576;
	mul.f32 	%f754, %f754, %f578;
	mul.f32 	%f755, %f755, %f578;
	mul.f32 	%f760, %f760, %f576;
	mul.f32 	%f761, %f761, %f576;
	mul.f32 	%f762, %f762, %f578;
	mul.f32 	%f763, %f763, %f578;
	mul.f32 	%f768, %f768, %f576;
	mul.f32 	%f769, %f769, %f576;
	mul.f32 	%f770, %f770, %f578;
	mul.f32 	%f771, %f771, %f578;
	mul.f32 	%f776, %f776, %f580;
	mul.f32 	%f777, %f777, %f580;
	mul.f32 	%f778, %f778, %f582;
	mul.f32 	%f779, %f779, %f582;
	mul.f32 	%f784, %f784, %f580;
	mul.f32 	%f785, %f785, %f580;
	mul.f32 	%f786, %f786, %f582;
	mul.f32 	%f787, %f787, %f582;
	mul.f32 	%f792, %f792, %f580;
	mul.f32 	%f793, %f793, %f580;
	mul.f32 	%f794, %f794, %f582;
	mul.f32 	%f795, %f795, %f582;
	mul.f32 	%f800, %f800, %f580;
	mul.f32 	%f801, %f801, %f580;
	mul.f32 	%f802, %f802, %f582;
	mul.f32 	%f803, %f803, %f582;
	mul.f32 	%f808, %f808, %f580;
	mul.f32 	%f809, %f809, %f580;
	mul.f32 	%f810, %f810, %f582;
	mul.f32 	%f811, %f811, %f582;
	mul.f32 	%f816, %f816, %f580;
	mul.f32 	%f817, %f817, %f580;
	mul.f32 	%f818, %f818, %f582;
	mul.f32 	%f819, %f819, %f582;
	mul.f32 	%f824, %f824, %f580;
	mul.f32 	%f825, %f825, %f580;
	mul.f32 	%f826, %f826, %f582;
	mul.f32 	%f827, %f827, %f582;
	mul.f32 	%f832, %f832, %f580;
	mul.f32 	%f833, %f833, %f580;
	mul.f32 	%f834, %f834, %f582;
	mul.f32 	%f835, %f835, %f582;
	.loc	1 82 28
	st.shared.v2.f32 	[%r14], {%f512, %f514};
	st.shared.v2.f32 	[%r14+1088], {%f516, %f518};
	st.shared.v2.f32 	[%r14+32], {%f520, %f522};
	st.shared.v2.f32 	[%r16+1088], {%f524, %f526};
	st.shared.v2.f32 	[%r14+64], {%f528, %f530};
	st.shared.v2.f32 	[%r18+1088], {%f532, %f534};
	st.shared.v2.f32 	[%r14+96], {%f536, %f538};
	st.shared.v2.f32 	[%r20+1088], {%f540, %f542};
	bar.sync 	0;
	ld.shared.v2.f32 	{%f1402, %f1403}, [%r22];
	ld.shared.v2.f32 	{%f1404, %f1405}, [%r22+136];
	ld.shared.v2.f32 	{%f1406, %f1407}, [%r22+2176];
	ld.shared.v2.f32 	{%f1408, %f1409}, [%r22+2312];
	ld.shared.v2.f32 	{%f1410, %f1411}, [%r22+4352];
	ld.shared.v2.f32 	{%f1412, %f1413}, [%r22+4488];
	ld.shared.v2.f32 	{%f1414, %f1415}, [%r22+6528];
	ld.shared.v2.f32 	{%f1416, %f1417}, [%r22+6664];
	bar.sync 	0;
	st.shared.v2.f32 	[%r14], {%f544, %f546};
	st.shared.v2.f32 	[%r14+1088], {%f548, %f550};
	st.shared.v2.f32 	[%r14+32], {%f552, %f554};
	st.shared.v2.f32 	[%r16+1088], {%f556, %f558};
	st.shared.v2.f32 	[%r14+64], {%f560, %f562};
	st.shared.v2.f32 	[%r18+1088], {%f564, %f566};
	st.shared.v2.f32 	[%r14+96], {%f568, %f570};
	st.shared.v2.f32 	[%r20+1088], {%f572, %f574};
	bar.sync 	0;
	ld.shared.v2.f32 	{%f1418, %f1419}, [%r22];
	ld.shared.v2.f32 	{%f1420, %f1421}, [%r22+136];
	ld.shared.v2.f32 	{%f1422, %f1423}, [%r22+2176];
	ld.shared.v2.f32 	{%f1424, %f1425}, [%r22+2312];
	ld.shared.v2.f32 	{%f1426, %f1427}, [%r22+4352];
	ld.shared.v2.f32 	{%f1428, %f1429}, [%r22+4488];
	ld.shared.v2.f32 	{%f1430, %f1431}, [%r22+6528];
	ld.shared.v2.f32 	{%f1432, %f1433}, [%r22+6664];
	bar.sync 	0;
	st.shared.v2.f32 	[%r23], {%f1402, %f1403};
	st.shared.v2.f32 	[%r24], {%f1404, %f1405};
	st.shared.v2.f32 	[%r25], {%f1406, %f1407};
	st.shared.v2.f32 	[%r26], {%f1408, %f1409};
	st.shared.v2.f32 	[%r27], {%f1410, %f1411};
	st.shared.v2.f32 	[%r28], {%f1412, %f1413};
	st.shared.v2.f32 	[%r29], {%f1414, %f1415};
	st.shared.v2.f32 	[%r30], {%f1416, %f1417};
	st.shared.v2.f32 	[%r31], {%f1418, %f1419};
	st.shared.v2.f32 	[%r32], {%f1420, %f1421};
	st.shared.v2.f32 	[%r33], {%f1422, %f1423};
	st.shared.v2.f32 	[%r34], {%f1424, %f1425};
	st.shared.v2.f32 	[%r35], {%f1426, %f1427};
	st.shared.v2.f32 	[%r36], {%f1428, %f1429};
	st.shared.v2.f32 	[%r37], {%f1430, %f1431};
	st.shared.v2.f32 	[%r38], {%f1432, %f1433};
	bar.sync 	0;
	ld.shared.v2.u32 	{%r688, %r690}, [%r39];
	ld.shared.v2.u32 	{%r689, %r691}, [%r39+1024];
	ld.shared.v2.u32 	{%r784, %r786}, [%r40];
	ld.shared.v2.u32 	{%r785, %r787}, [%r40+1024];
	ld.shared.v2.u32 	{%r880, %r882}, [%r41];
	ld.shared.v2.u32 	{%r881, %r883}, [%r41+1024];
	ld.shared.v2.u32 	{%r976, %r978}, [%r42];
	ld.shared.v2.u32 	{%r977, %r979}, [%r42+1024];
	ld.shared.v2.u32 	{%r736, %r738}, [%r39+8192];
	ld.shared.v2.u32 	{%r737, %r739}, [%r39+9216];
	ld.shared.v2.u32 	{%r832, %r834}, [%r40+8192];
	ld.shared.v2.u32 	{%r833, %r835}, [%r40+9216];
	ld.shared.v2.u32 	{%r928, %r930}, [%r41+8192];
	ld.shared.v2.u32 	{%r929, %r931}, [%r41+9216];
	ld.shared.v2.u32 	{%r1024, %r1026}, [%r42+8192];
	ld.shared.v2.u32 	{%r1025, %r1027}, [%r42+9216];
	.loc	1 83 25
	add.s32 	%r588, %r1497, %r1141;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r584, %r585, %r586, %r587 }, [ %r588 + 0 ];
	// end inline asm
	add.s32 	%r593, %r588, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r589, %r590, %r591, %r592 }, [ %r593 + 0 ];
	// end inline asm
	add.s32 	%r598, %r1497, %r1142;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r594, %r595, %r596, %r597 }, [ %r598 + 0 ];
	// end inline asm
	add.s32 	%r603, %r598, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r599, %r600, %r601, %r602 }, [ %r603 + 0 ];
	// end inline asm
	add.s32 	%r608, %r1497, %r1143;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r604, %r605, %r606, %r607 }, [ %r608 + 0 ];
	// end inline asm
	add.s32 	%r613, %r608, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r609, %r610, %r611, %r612 }, [ %r613 + 0 ];
	// end inline asm
	add.s32 	%r618, %r1497, %r1144;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r614, %r615, %r616, %r617 }, [ %r618 + 0 ];
	// end inline asm
	add.s32 	%r623, %r618, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r619, %r620, %r621, %r622 }, [ %r623 + 0 ];
	// end inline asm
	cvt.u16.u32 	%rs11, %r584;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs12}, %r584; }
	cvt.u16.u32 	%rs13, %r585;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs14}, %r585; }
	cvt.u16.u32 	%rs15, %r586;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs16}, %r586; }
	cvt.u16.u32 	%rs17, %r587;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs18}, %r587; }
	cvt.u16.u32 	%rs19, %r589;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs20}, %r589; }
	cvt.u16.u32 	%rs21, %r590;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs22}, %r590; }
	cvt.u16.u32 	%rs23, %r591;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs24}, %r591; }
	cvt.u16.u32 	%rs25, %r592;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs26}, %r592; }
	cvt.u16.u32 	%rs27, %r594;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs28}, %r594; }
	cvt.u16.u32 	%rs29, %r595;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs30}, %r595; }
	cvt.u16.u32 	%rs31, %r596;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs32}, %r596; }
	cvt.u16.u32 	%rs33, %r597;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs34}, %r597; }
	cvt.u16.u32 	%rs35, %r599;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs36}, %r599; }
	cvt.u16.u32 	%rs37, %r600;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs38}, %r600; }
	cvt.u16.u32 	%rs39, %r601;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs40}, %r601; }
	cvt.u16.u32 	%rs41, %r602;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs42}, %r602; }
	cvt.u16.u32 	%rs43, %r604;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs44}, %r604; }
	cvt.u16.u32 	%rs45, %r605;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs46}, %r605; }
	cvt.u16.u32 	%rs47, %r606;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs48}, %r606; }
	cvt.u16.u32 	%rs49, %r607;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs50}, %r607; }
	cvt.u16.u32 	%rs51, %r609;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs52}, %r609; }
	cvt.u16.u32 	%rs53, %r610;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs54}, %r610; }
	cvt.u16.u32 	%rs55, %r611;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs56}, %r611; }
	cvt.u16.u32 	%rs57, %r612;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs58}, %r612; }
	cvt.u16.u32 	%rs59, %r614;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs60}, %r614; }
	cvt.u16.u32 	%rs61, %r615;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs62}, %r615; }
	cvt.u16.u32 	%rs63, %r616;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs64}, %r616; }
	cvt.u16.u32 	%rs65, %r617;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs66}, %r617; }
	cvt.u16.u32 	%rs67, %r619;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs68}, %r619; }
	cvt.u16.u32 	%rs69, %r620;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs70}, %r620; }
	cvt.u16.u32 	%rs71, %r621;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs72}, %r621; }
	cvt.u16.u32 	%rs73, %r622;
	{ .reg .b16 tmp; mov.b32 {tmp, %rs74}, %r622; }
	// begin inline asm
	cvt.f32.bf16 %r692, %rs11;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r693, %rs12;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r788, %rs13;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r789, %rs14;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r698, %rs15;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r699, %rs16;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r794, %rs17;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r795, %rs18;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r884, %rs19;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r885, %rs20;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r980, %rs21;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r981, %rs22;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r890, %rs23;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r891, %rs24;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r986, %rs25;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r987, %rs26;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r704, %rs27;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r705, %rs28;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r800, %rs29;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r801, %rs30;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r710, %rs31;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r711, %rs32;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r806, %rs33;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r807, %rs34;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r896, %rs35;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r897, %rs36;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r992, %rs37;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r993, %rs38;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r902, %rs39;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r903, %rs40;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r998, %rs41;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r999, %rs42;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r716, %rs43;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r717, %rs44;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r812, %rs45;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r813, %rs46;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r722, %rs47;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r723, %rs48;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r818, %rs49;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r819, %rs50;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r908, %rs51;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r909, %rs52;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r1004, %rs53;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r1005, %rs54;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r914, %rs55;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r915, %rs56;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r1010, %rs57;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r1011, %rs58;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r728, %rs59;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r729, %rs60;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r824, %rs61;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r825, %rs62;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r734, %rs63;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r735, %rs64;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r830, %rs65;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r831, %rs66;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r920, %rs67;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r921, %rs68;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r1016, %rs69;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r1017, %rs70;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r926, %rs71;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r927, %rs72;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r1022, %rs73;
	// end inline asm
	// begin inline asm
	cvt.f32.bf16 %r1023, %rs74;
	// end inline asm
	.loc	1 86 30
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f712, %f713, %f714, %f715 }, { %r688, %r689, %r690, %r691 }, { %r692, %r693 }, { %f712, %f713, %f714, %f715 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f720, %f721, %f722, %f723 }, { %r688, %r689, %r690, %r691 }, { %r698, %r699 }, { %f720, %f721, %f722, %f723 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f728, %f729, %f730, %f731 }, { %r688, %r689, %r690, %r691 }, { %r704, %r705 }, { %f728, %f729, %f730, %f731 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f736, %f737, %f738, %f739 }, { %r688, %r689, %r690, %r691 }, { %r710, %r711 }, { %f736, %f737, %f738, %f739 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f744, %f745, %f746, %f747 }, { %r688, %r689, %r690, %r691 }, { %r716, %r717 }, { %f744, %f745, %f746, %f747 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f752, %f753, %f754, %f755 }, { %r688, %r689, %r690, %r691 }, { %r722, %r723 }, { %f752, %f753, %f754, %f755 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f760, %f761, %f762, %f763 }, { %r688, %r689, %r690, %r691 }, { %r728, %r729 }, { %f760, %f761, %f762, %f763 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f768, %f769, %f770, %f771 }, { %r688, %r689, %r690, %r691 }, { %r734, %r735 }, { %f768, %f769, %f770, %f771 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f776, %f777, %f778, %f779 }, { %r736, %r737, %r738, %r739 }, { %r692, %r693 }, { %f776, %f777, %f778, %f779 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f784, %f785, %f786, %f787 }, { %r736, %r737, %r738, %r739 }, { %r698, %r699 }, { %f784, %f785, %f786, %f787 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f792, %f793, %f794, %f795 }, { %r736, %r737, %r738, %r739 }, { %r704, %r705 }, { %f792, %f793, %f794, %f795 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f800, %f801, %f802, %f803 }, { %r736, %r737, %r738, %r739 }, { %r710, %r711 }, { %f800, %f801, %f802, %f803 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f808, %f809, %f810, %f811 }, { %r736, %r737, %r738, %r739 }, { %r716, %r717 }, { %f808, %f809, %f810, %f811 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f816, %f817, %f818, %f819 }, { %r736, %r737, %r738, %r739 }, { %r722, %r723 }, { %f816, %f817, %f818, %f819 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f824, %f825, %f826, %f827 }, { %r736, %r737, %r738, %r739 }, { %r728, %r729 }, { %f824, %f825, %f826, %f827 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f832, %f833, %f834, %f835 }, { %r736, %r737, %r738, %r739 }, { %r734, %r735 }, { %f832, %f833, %f834, %f835 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f712, %f713, %f714, %f715 }, { %r784, %r785, %r786, %r787 }, { %r788, %r789 }, { %f712, %f713, %f714, %f715 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f720, %f721, %f722, %f723 }, { %r784, %r785, %r786, %r787 }, { %r794, %r795 }, { %f720, %f721, %f722, %f723 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f728, %f729, %f730, %f731 }, { %r784, %r785, %r786, %r787 }, { %r800, %r801 }, { %f728, %f729, %f730, %f731 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f736, %f737, %f738, %f739 }, { %r784, %r785, %r786, %r787 }, { %r806, %r807 }, { %f736, %f737, %f738, %f739 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f744, %f745, %f746, %f747 }, { %r784, %r785, %r786, %r787 }, { %r812, %r813 }, { %f744, %f745, %f746, %f747 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f752, %f753, %f754, %f755 }, { %r784, %r785, %r786, %r787 }, { %r818, %r819 }, { %f752, %f753, %f754, %f755 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f760, %f761, %f762, %f763 }, { %r784, %r785, %r786, %r787 }, { %r824, %r825 }, { %f760, %f761, %f762, %f763 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f768, %f769, %f770, %f771 }, { %r784, %r785, %r786, %r787 }, { %r830, %r831 }, { %f768, %f769, %f770, %f771 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f776, %f777, %f778, %f779 }, { %r832, %r833, %r834, %r835 }, { %r788, %r789 }, { %f776, %f777, %f778, %f779 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f784, %f785, %f786, %f787 }, { %r832, %r833, %r834, %r835 }, { %r794, %r795 }, { %f784, %f785, %f786, %f787 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f792, %f793, %f794, %f795 }, { %r832, %r833, %r834, %r835 }, { %r800, %r801 }, { %f792, %f793, %f794, %f795 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f800, %f801, %f802, %f803 }, { %r832, %r833, %r834, %r835 }, { %r806, %r807 }, { %f800, %f801, %f802, %f803 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f808, %f809, %f810, %f811 }, { %r832, %r833, %r834, %r835 }, { %r812, %r813 }, { %f808, %f809, %f810, %f811 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f816, %f817, %f818, %f819 }, { %r832, %r833, %r834, %r835 }, { %r818, %r819 }, { %f816, %f817, %f818, %f819 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f824, %f825, %f826, %f827 }, { %r832, %r833, %r834, %r835 }, { %r824, %r825 }, { %f824, %f825, %f826, %f827 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f832, %f833, %f834, %f835 }, { %r832, %r833, %r834, %r835 }, { %r830, %r831 }, { %f832, %f833, %f834, %f835 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f712, %f713, %f714, %f715 }, { %r880, %r881, %r882, %r883 }, { %r884, %r885 }, { %f712, %f713, %f714, %f715 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f720, %f721, %f722, %f723 }, { %r880, %r881, %r882, %r883 }, { %r890, %r891 }, { %f720, %f721, %f722, %f723 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f728, %f729, %f730, %f731 }, { %r880, %r881, %r882, %r883 }, { %r896, %r897 }, { %f728, %f729, %f730, %f731 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f736, %f737, %f738, %f739 }, { %r880, %r881, %r882, %r883 }, { %r902, %r903 }, { %f736, %f737, %f738, %f739 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f744, %f745, %f746, %f747 }, { %r880, %r881, %r882, %r883 }, { %r908, %r909 }, { %f744, %f745, %f746, %f747 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f752, %f753, %f754, %f755 }, { %r880, %r881, %r882, %r883 }, { %r914, %r915 }, { %f752, %f753, %f754, %f755 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f760, %f761, %f762, %f763 }, { %r880, %r881, %r882, %r883 }, { %r920, %r921 }, { %f760, %f761, %f762, %f763 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f768, %f769, %f770, %f771 }, { %r880, %r881, %r882, %r883 }, { %r926, %r927 }, { %f768, %f769, %f770, %f771 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f776, %f777, %f778, %f779 }, { %r928, %r929, %r930, %r931 }, { %r884, %r885 }, { %f776, %f777, %f778, %f779 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f784, %f785, %f786, %f787 }, { %r928, %r929, %r930, %r931 }, { %r890, %r891 }, { %f784, %f785, %f786, %f787 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f792, %f793, %f794, %f795 }, { %r928, %r929, %r930, %r931 }, { %r896, %r897 }, { %f792, %f793, %f794, %f795 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f800, %f801, %f802, %f803 }, { %r928, %r929, %r930, %r931 }, { %r902, %r903 }, { %f800, %f801, %f802, %f803 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f808, %f809, %f810, %f811 }, { %r928, %r929, %r930, %r931 }, { %r908, %r909 }, { %f808, %f809, %f810, %f811 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f816, %f817, %f818, %f819 }, { %r928, %r929, %r930, %r931 }, { %r914, %r915 }, { %f816, %f817, %f818, %f819 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f824, %f825, %f826, %f827 }, { %r928, %r929, %r930, %r931 }, { %r920, %r921 }, { %f824, %f825, %f826, %f827 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f832, %f833, %f834, %f835 }, { %r928, %r929, %r930, %r931 }, { %r926, %r927 }, { %f832, %f833, %f834, %f835 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f712, %f713, %f714, %f715 }, { %r976, %r977, %r978, %r979 }, { %r980, %r981 }, { %f712, %f713, %f714, %f715 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f720, %f721, %f722, %f723 }, { %r976, %r977, %r978, %r979 }, { %r986, %r987 }, { %f720, %f721, %f722, %f723 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f728, %f729, %f730, %f731 }, { %r976, %r977, %r978, %r979 }, { %r992, %r993 }, { %f728, %f729, %f730, %f731 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f736, %f737, %f738, %f739 }, { %r976, %r977, %r978, %r979 }, { %r998, %r999 }, { %f736, %f737, %f738, %f739 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f744, %f745, %f746, %f747 }, { %r976, %r977, %r978, %r979 }, { %r1004, %r1005 }, { %f744, %f745, %f746, %f747 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f752, %f753, %f754, %f755 }, { %r976, %r977, %r978, %r979 }, { %r1010, %r1011 }, { %f752, %f753, %f754, %f755 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f760, %f761, %f762, %f763 }, { %r976, %r977, %r978, %r979 }, { %r1016, %r1017 }, { %f760, %f761, %f762, %f763 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f768, %f769, %f770, %f771 }, { %r976, %r977, %r978, %r979 }, { %r1022, %r1023 }, { %f768, %f769, %f770, %f771 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f776, %f777, %f778, %f779 }, { %r1024, %r1025, %r1026, %r1027 }, { %r980, %r981 }, { %f776, %f777, %f778, %f779 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f784, %f785, %f786, %f787 }, { %r1024, %r1025, %r1026, %r1027 }, { %r986, %r987 }, { %f784, %f785, %f786, %f787 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f792, %f793, %f794, %f795 }, { %r1024, %r1025, %r1026, %r1027 }, { %r992, %r993 }, { %f792, %f793, %f794, %f795 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f800, %f801, %f802, %f803 }, { %r1024, %r1025, %r1026, %r1027 }, { %r998, %r999 }, { %f800, %f801, %f802, %f803 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f808, %f809, %f810, %f811 }, { %r1024, %r1025, %r1026, %r1027 }, { %r1004, %r1005 }, { %f808, %f809, %f810, %f811 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f816, %f817, %f818, %f819 }, { %r1024, %r1025, %r1026, %r1027 }, { %r1010, %r1011 }, { %f816, %f817, %f818, %f819 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f824, %f825, %f826, %f827 }, { %r1024, %r1025, %r1026, %r1027 }, { %r1016, %r1017 }, { %f824, %f825, %f826, %f827 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { %f832, %f833, %f834, %f835 }, { %r1024, %r1025, %r1026, %r1027 }, { %r1022, %r1023 }, { %f832, %f833, %f834, %f835 };
	// end inline asm
	.loc	1 93 24
	sub.f32 	%f1434, %f1201, %f114;
	sub.f32 	%f1435, %f1202, %f114;
	sub.f32 	%f1436, %f1203, %f113;
	sub.f32 	%f1437, %f1204, %f113;
	sub.f32 	%f1438, %f1205, %f114;
	sub.f32 	%f1439, %f1206, %f114;
	sub.f32 	%f1440, %f1207, %f113;
	sub.f32 	%f1441, %f1208, %f113;
	sub.f32 	%f1442, %f1209, %f114;
	sub.f32 	%f1443, %f1210, %f114;
	sub.f32 	%f1444, %f1211, %f113;
	sub.f32 	%f1445, %f1212, %f113;
	sub.f32 	%f1446, %f1213, %f114;
	sub.f32 	%f1447, %f1214, %f114;
	sub.f32 	%f1448, %f1215, %f113;
	sub.f32 	%f1449, %f1216, %f113;
	sub.f32 	%f1450, %f1217, %f112;
	sub.f32 	%f1451, %f1218, %f112;
	sub.f32 	%f1452, %f1219, %f111;
	sub.f32 	%f1453, %f1220, %f111;
	sub.f32 	%f1454, %f1221, %f112;
	sub.f32 	%f1455, %f1222, %f112;
	sub.f32 	%f1456, %f1223, %f111;
	sub.f32 	%f1457, %f1224, %f111;
	sub.f32 	%f1458, %f1225, %f112;
	sub.f32 	%f1459, %f1226, %f112;
	sub.f32 	%f1460, %f1227, %f111;
	sub.f32 	%f1461, %f1228, %f111;
	sub.f32 	%f1462, %f1229, %f112;
	sub.f32 	%f1463, %f1230, %f112;
	sub.f32 	%f1464, %f1231, %f111;
	sub.f32 	%f1465, %f1232, %f111;
	.loc	1 94 28
	mul.f32 	%f1097, %f1434, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1096, %f1097;
	// end inline asm
	mul.f32 	%f1099, %f1435, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1098, %f1099;
	// end inline asm
	mul.f32 	%f1101, %f1436, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1100, %f1101;
	// end inline asm
	mul.f32 	%f1103, %f1437, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1102, %f1103;
	// end inline asm
	mul.f32 	%f1105, %f1438, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1104, %f1105;
	// end inline asm
	mul.f32 	%f1107, %f1439, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1106, %f1107;
	// end inline asm
	mul.f32 	%f1109, %f1440, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1108, %f1109;
	// end inline asm
	mul.f32 	%f1111, %f1441, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1110, %f1111;
	// end inline asm
	mul.f32 	%f1113, %f1442, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1112, %f1113;
	// end inline asm
	mul.f32 	%f1115, %f1443, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1114, %f1115;
	// end inline asm
	mul.f32 	%f1117, %f1444, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1116, %f1117;
	// end inline asm
	mul.f32 	%f1119, %f1445, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1118, %f1119;
	// end inline asm
	mul.f32 	%f1121, %f1446, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1120, %f1121;
	// end inline asm
	mul.f32 	%f1123, %f1447, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1122, %f1123;
	// end inline asm
	mul.f32 	%f1125, %f1448, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1124, %f1125;
	// end inline asm
	mul.f32 	%f1127, %f1449, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1126, %f1127;
	// end inline asm
	mul.f32 	%f1129, %f1450, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1128, %f1129;
	// end inline asm
	mul.f32 	%f1131, %f1451, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1130, %f1131;
	// end inline asm
	mul.f32 	%f1133, %f1452, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1132, %f1133;
	// end inline asm
	mul.f32 	%f1135, %f1453, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1134, %f1135;
	// end inline asm
	mul.f32 	%f1137, %f1454, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1136, %f1137;
	// end inline asm
	mul.f32 	%f1139, %f1455, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1138, %f1139;
	// end inline asm
	mul.f32 	%f1141, %f1456, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1140, %f1141;
	// end inline asm
	mul.f32 	%f1143, %f1457, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1142, %f1143;
	// end inline asm
	mul.f32 	%f1145, %f1458, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1144, %f1145;
	// end inline asm
	mul.f32 	%f1147, %f1459, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1146, %f1147;
	// end inline asm
	mul.f32 	%f1149, %f1460, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1148, %f1149;
	// end inline asm
	mul.f32 	%f1151, %f1461, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1150, %f1151;
	// end inline asm
	mul.f32 	%f1153, %f1462, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1152, %f1153;
	// end inline asm
	mul.f32 	%f1155, %f1463, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1154, %f1155;
	// end inline asm
	mul.f32 	%f1157, %f1464, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1156, %f1157;
	// end inline asm
	mul.f32 	%f1159, %f1465, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1158, %f1159;
	// end inline asm
	.loc	1 98 25
	fma.rn.f32 	%f1677, %f1677, %f582, %f1158;
	fma.rn.f32 	%f1676, %f1676, %f582, %f1156;
	fma.rn.f32 	%f1675, %f1675, %f580, %f1154;
	fma.rn.f32 	%f1674, %f1674, %f580, %f1152;
	fma.rn.f32 	%f1673, %f1673, %f582, %f1150;
	fma.rn.f32 	%f1672, %f1672, %f582, %f1148;
	fma.rn.f32 	%f1671, %f1671, %f580, %f1146;
	fma.rn.f32 	%f1670, %f1670, %f580, %f1144;
	fma.rn.f32 	%f1669, %f1669, %f582, %f1142;
	fma.rn.f32 	%f1668, %f1668, %f582, %f1140;
	fma.rn.f32 	%f1667, %f1667, %f580, %f1138;
	fma.rn.f32 	%f1666, %f1666, %f580, %f1136;
	fma.rn.f32 	%f1665, %f1665, %f582, %f1134;
	fma.rn.f32 	%f1664, %f1664, %f582, %f1132;
	fma.rn.f32 	%f1663, %f1663, %f580, %f1130;
	fma.rn.f32 	%f1662, %f1662, %f580, %f1128;
	fma.rn.f32 	%f1661, %f1661, %f578, %f1126;
	fma.rn.f32 	%f1660, %f1660, %f578, %f1124;
	fma.rn.f32 	%f1659, %f1659, %f576, %f1122;
	fma.rn.f32 	%f1658, %f1658, %f576, %f1120;
	fma.rn.f32 	%f1657, %f1657, %f578, %f1118;
	fma.rn.f32 	%f1656, %f1656, %f578, %f1116;
	fma.rn.f32 	%f1655, %f1655, %f576, %f1114;
	fma.rn.f32 	%f1654, %f1654, %f576, %f1112;
	fma.rn.f32 	%f1653, %f1653, %f578, %f1110;
	fma.rn.f32 	%f1652, %f1652, %f578, %f1108;
	fma.rn.f32 	%f1651, %f1651, %f576, %f1106;
	fma.rn.f32 	%f1650, %f1650, %f576, %f1104;
	fma.rn.f32 	%f1649, %f1649, %f578, %f1102;
	fma.rn.f32 	%f1648, %f1648, %f578, %f1100;
	fma.rn.f32 	%f1647, %f1647, %f576, %f1098;
	fma.rn.f32 	%f1646, %f1646, %f576, %f1096;
	.loc	1 36 33
	add.s32 	%r1145, %r1501, 1;
	setp.lt.s32 	%p126, %r1145, 2;
	selp.b32 	%r1501, %r1145, 0, %p126;
	.loc	1 37 27
	add.s32 	%r1146, %r55, %r1496;
	add.s32 	%r1147, %r1146, 96;
	.loc	1 38 25
	add.s32 	%r1148, %r1146, 112;
	setp.lt.u32 	%p127, %r1147, 512;
	setp.lt.u32 	%p128, %r1148, 512;
	.loc	1 48 84
	shl.b32 	%r1149, %r1501, 14;
	add.s32 	%r1151, %r121, %r1149;
	add.s32 	%r1072, %r1151, %r187;
	add.s32 	%r1074, %r1151, %r189;
	add.s32 	%r1076, %r1151, %r191;
	add.s32 	%r1078, %r1151, %r193;
	add.s32 	%r1080, %r1151, %r195;
	add.s32 	%r1082, %r1151, %r197;
	add.s32 	%r1084, %r1151, %r199;
	add.s32 	%r1086, %r1151, %r201;
	selp.b32 	%r1073, 16, 0, %p37;
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r1072 + 0 ], [ %rd55 + 0 ], 0x10, %r1073;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r1074 + 0 ], [ %rd56 + 0 ], 0x10, %r1073;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r1076 + 0 ], [ %rd57 + 0 ], 0x10, %r1073;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r1078 + 0 ], [ %rd58 + 0 ], 0x10, %r1073;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r1080 + 0 ], [ %rd59 + 0 ], 0x10, %r1073;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r1082 + 0 ], [ %rd60 + 0 ], 0x10, %r1073;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r1084 + 0 ], [ %rd61 + 0 ], 0x10, %r1073;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r1086 + 0 ], [ %rd62 + 0 ], 0x10, %r1073;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 49 38
	add.s64 	%rd63, %rd16, %rd99;
	.loc	1 49 84
	add.s64 	%rd64, %rd16, %rd100;
	shl.b32 	%r1160, %r1501, 12;
	add.s32 	%r1162, %r120, %r1160;
	add.s32 	%r1088, %r1162, %r187;
	add.s32 	%r1090, %r1162, %r189;
	selp.b32 	%r1163, 16, 0, %p127;
	selp.b32 	%r1093, %r1163, 0, %p37;
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r1088 + 0 ], [ %rd63 + 0 ], 0x10, %r1093;
	// end inline asm
	selp.b32 	%r1164, 16, 0, %p128;
	selp.b32 	%r1095, %r1164, 0, %p37;
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r1090 + 0 ], [ %rd64 + 0 ], 0x10, %r1095;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 55 35
	add.s64 	%rd65, %rd17, %rd99;
	.loc	1 55 81
	add.s64 	%rd66, %rd17, %rd100;
	add.s32 	%r1166, %r119, %r1160;
	bar.sync 	0;
	add.s32 	%r1092, %r1166, %r187;
	add.s32 	%r1094, %r1166, %r189;
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r1092 + 0 ], [ %rd65 + 0 ], 0x10, %r1093;
	// end inline asm
	// begin inline asm
	@%p131 cp.async.cg.shared.global [ %r1094 + 0 ], [ %rd66 + 0 ], 0x10, %r1095;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 36 33
	add.s32 	%r1167, %r1500, 1;
	setp.lt.s32 	%p129, %r1167, 2;
	selp.b32 	%r1500, %r1167, 0, %p129;
	.loc	1 48 84
	shl.b32 	%r1168, %r1500, 14;
	add.s32 	%r1499, %r121, %r1168;
	.loc	1 49 84
	shl.b32 	%r1169, %r1500, 12;
	add.s32 	%r1498, %r120, %r1169;
	.loc	1 48 84
	// begin inline asm
	cp.async.wait_group 0x3;
	// end inline asm
	bar.sync 	0;
	.loc	1 55 81
	add.s32 	%r1497, %r119, %r1169;
	.loc	1 36 33
	add.s64 	%rd100, %rd100, 4096;
	add.s64 	%rd99, %rd99, 4096;
	setp.lt.u32 	%p130, %r63, 480;
	mov.u32 	%r1496, %r63;
	mov.f32 	%f1642, %f111;
	mov.f32 	%f1643, %f112;
	mov.f32 	%f1644, %f113;
	mov.f32 	%f1645, %f114;
	@%p130 bra 	$L__BB0_1;
	.loc	1 28 22
	shl.b32 	%r1426, %r2, 2;
	and.b32  	%r1427, %r1426, 60;
	.loc	1 27 33
	bfe.u32 	%r1428, %r2, 4, 3;
	.loc	1 27 20
	or.b32  	%r1429, %r1, %r1428;
	.loc	1 36 33
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
$L__tmp6:
	.loc	3 256 15
	add.f32 	%f1466, %f1646, %f1647;
	add.f32 	%f1467, %f1648, %f1649;
	add.f32 	%f1468, %f1650, %f1466;
	add.f32 	%f1469, %f1651, %f1468;
	add.f32 	%f1470, %f1652, %f1467;
	add.f32 	%f1471, %f1653, %f1470;
	add.f32 	%f1472, %f1654, %f1469;
	add.f32 	%f1473, %f1655, %f1472;
	add.f32 	%f1474, %f1656, %f1471;
	add.f32 	%f1475, %f1657, %f1474;
	add.f32 	%f1476, %f1658, %f1473;
	add.f32 	%f1477, %f1659, %f1476;
	add.f32 	%f1478, %f1660, %f1475;
	add.f32 	%f1479, %f1661, %f1478;
	add.f32 	%f1480, %f1662, %f1663;
	add.f32 	%f1481, %f1664, %f1665;
	add.f32 	%f1482, %f1666, %f1480;
	add.f32 	%f1483, %f1667, %f1482;
	add.f32 	%f1484, %f1668, %f1481;
	add.f32 	%f1485, %f1669, %f1484;
	add.f32 	%f1486, %f1670, %f1483;
	add.f32 	%f1487, %f1671, %f1486;
	add.f32 	%f1488, %f1672, %f1485;
	add.f32 	%f1489, %f1673, %f1488;
	add.f32 	%f1490, %f1674, %f1487;
	add.f32 	%f1491, %f1675, %f1490;
	add.f32 	%f1492, %f1676, %f1489;
	add.f32 	%f1493, %f1677, %f1492;
	.loc	3 267 36
	mov.b32 	%r1430, %f1477;
	shfl.sync.bfly.b32	%r1431, %r1430, 2, 31, -1;
	mov.b32 	%f1494, %r1431;
	.loc	3 256 15
	add.f32 	%f1495, %f1477, %f1494;
	.loc	3 267 36
	mov.b32 	%r1432, %f1495;
	shfl.sync.bfly.b32	%r1433, %r1432, 1, 31, -1;
	mov.b32 	%f1496, %r1433;
	.loc	3 256 15
	add.f32 	%f1497, %f1495, %f1496;
	.loc	3 267 36
	mov.b32 	%r1434, %f1479;
	shfl.sync.bfly.b32	%r1435, %r1434, 2, 31, -1;
	mov.b32 	%f1498, %r1435;
	.loc	3 256 15
	add.f32 	%f1499, %f1479, %f1498;
	.loc	3 267 36
	mov.b32 	%r1436, %f1499;
	shfl.sync.bfly.b32	%r1437, %r1436, 1, 31, -1;
	mov.b32 	%f1500, %r1437;
	.loc	3 256 15
	add.f32 	%f1501, %f1499, %f1500;
	.loc	3 267 36
	mov.b32 	%r1438, %f1491;
	shfl.sync.bfly.b32	%r1439, %r1438, 2, 31, -1;
	mov.b32 	%f1502, %r1439;
	.loc	3 256 15
	add.f32 	%f1503, %f1491, %f1502;
	.loc	3 267 36
	mov.b32 	%r1440, %f1503;
	shfl.sync.bfly.b32	%r1441, %r1440, 1, 31, -1;
	mov.b32 	%f1504, %r1441;
	.loc	3 256 15
	add.f32 	%f1505, %f1503, %f1504;
	.loc	3 267 36
	mov.b32 	%r1442, %f1493;
	shfl.sync.bfly.b32	%r1443, %r1442, 2, 31, -1;
	mov.b32 	%f1506, %r1443;
	.loc	3 256 15
	add.f32 	%f1507, %f1493, %f1506;
	.loc	3 267 36
	mov.b32 	%r1444, %f1507;
	shfl.sync.bfly.b32	%r1445, %r1444, 1, 31, -1;
	mov.b32 	%f1508, %r1445;
	.loc	3 256 15
	add.f32 	%f1509, %f1507, %f1508;
$L__tmp7:
	.loc	1 102 20
	mov.b32 	%r1172, %f1497;
	mov.b32 	%r1171, %f712;
	// begin inline asm
	div.full.f32 %r1170, %r1171, %r1172;
	// end inline asm
	mov.b32 	%f1510, %r1170;
	mov.b32 	%r1174, %f713;
	// begin inline asm
	div.full.f32 %r1173, %r1174, %r1172;
	// end inline asm
	mov.b32 	%f1511, %r1173;
	mov.b32 	%r1178, %f1501;
	mov.b32 	%r1177, %f714;
	// begin inline asm
	div.full.f32 %r1176, %r1177, %r1178;
	// end inline asm
	mov.b32 	%f1512, %r1176;
	mov.b32 	%r1180, %f715;
	// begin inline asm
	div.full.f32 %r1179, %r1180, %r1178;
	// end inline asm
	mov.b32 	%f1513, %r1179;
	mov.b32 	%r1183, %f720;
	// begin inline asm
	div.full.f32 %r1182, %r1183, %r1172;
	// end inline asm
	mov.b32 	%f1514, %r1182;
	mov.b32 	%r1186, %f721;
	// begin inline asm
	div.full.f32 %r1185, %r1186, %r1172;
	// end inline asm
	mov.b32 	%f1515, %r1185;
	mov.b32 	%r1189, %f722;
	// begin inline asm
	div.full.f32 %r1188, %r1189, %r1178;
	// end inline asm
	mov.b32 	%f1516, %r1188;
	mov.b32 	%r1192, %f723;
	// begin inline asm
	div.full.f32 %r1191, %r1192, %r1178;
	// end inline asm
	mov.b32 	%f1517, %r1191;
	mov.b32 	%r1195, %f728;
	// begin inline asm
	div.full.f32 %r1194, %r1195, %r1172;
	// end inline asm
	mov.b32 	%f1518, %r1194;
	mov.b32 	%r1198, %f729;
	// begin inline asm
	div.full.f32 %r1197, %r1198, %r1172;
	// end inline asm
	mov.b32 	%f1519, %r1197;
	mov.b32 	%r1201, %f730;
	// begin inline asm
	div.full.f32 %r1200, %r1201, %r1178;
	// end inline asm
	mov.b32 	%f1520, %r1200;
	mov.b32 	%r1204, %f731;
	// begin inline asm
	div.full.f32 %r1203, %r1204, %r1178;
	// end inline asm
	mov.b32 	%f1521, %r1203;
	mov.b32 	%r1207, %f736;
	// begin inline asm
	div.full.f32 %r1206, %r1207, %r1172;
	// end inline asm
	mov.b32 	%f1522, %r1206;
	mov.b32 	%r1210, %f737;
	// begin inline asm
	div.full.f32 %r1209, %r1210, %r1172;
	// end inline asm
	mov.b32 	%f1523, %r1209;
	mov.b32 	%r1213, %f738;
	// begin inline asm
	div.full.f32 %r1212, %r1213, %r1178;
	// end inline asm
	mov.b32 	%f1524, %r1212;
	mov.b32 	%r1216, %f739;
	// begin inline asm
	div.full.f32 %r1215, %r1216, %r1178;
	// end inline asm
	mov.b32 	%f1525, %r1215;
	mov.b32 	%r1219, %f744;
	// begin inline asm
	div.full.f32 %r1218, %r1219, %r1172;
	// end inline asm
	mov.b32 	%f1526, %r1218;
	mov.b32 	%r1222, %f745;
	// begin inline asm
	div.full.f32 %r1221, %r1222, %r1172;
	// end inline asm
	mov.b32 	%f1527, %r1221;
	mov.b32 	%r1225, %f746;
	// begin inline asm
	div.full.f32 %r1224, %r1225, %r1178;
	// end inline asm
	mov.b32 	%f1528, %r1224;
	mov.b32 	%r1228, %f747;
	// begin inline asm
	div.full.f32 %r1227, %r1228, %r1178;
	// end inline asm
	mov.b32 	%f1529, %r1227;
	mov.b32 	%r1231, %f752;
	// begin inline asm
	div.full.f32 %r1230, %r1231, %r1172;
	// end inline asm
	mov.b32 	%f1530, %r1230;
	mov.b32 	%r1234, %f753;
	// begin inline asm
	div.full.f32 %r1233, %r1234, %r1172;
	// end inline asm
	mov.b32 	%f1531, %r1233;
	mov.b32 	%r1237, %f754;
	// begin inline asm
	div.full.f32 %r1236, %r1237, %r1178;
	// end inline asm
	mov.b32 	%f1532, %r1236;
	mov.b32 	%r1240, %f755;
	// begin inline asm
	div.full.f32 %r1239, %r1240, %r1178;
	// end inline asm
	mov.b32 	%f1533, %r1239;
	mov.b32 	%r1243, %f760;
	// begin inline asm
	div.full.f32 %r1242, %r1243, %r1172;
	// end inline asm
	mov.b32 	%f1534, %r1242;
	mov.b32 	%r1246, %f761;
	// begin inline asm
	div.full.f32 %r1245, %r1246, %r1172;
	// end inline asm
	mov.b32 	%f1535, %r1245;
	mov.b32 	%r1249, %f762;
	// begin inline asm
	div.full.f32 %r1248, %r1249, %r1178;
	// end inline asm
	mov.b32 	%f1536, %r1248;
	mov.b32 	%r1252, %f763;
	// begin inline asm
	div.full.f32 %r1251, %r1252, %r1178;
	// end inline asm
	mov.b32 	%f1537, %r1251;
	mov.b32 	%r1255, %f768;
	// begin inline asm
	div.full.f32 %r1254, %r1255, %r1172;
	// end inline asm
	mov.b32 	%f1538, %r1254;
	mov.b32 	%r1258, %f769;
	// begin inline asm
	div.full.f32 %r1257, %r1258, %r1172;
	// end inline asm
	mov.b32 	%f1539, %r1257;
	mov.b32 	%r1261, %f770;
	// begin inline asm
	div.full.f32 %r1260, %r1261, %r1178;
	// end inline asm
	mov.b32 	%f1540, %r1260;
	mov.b32 	%r1264, %f771;
	// begin inline asm
	div.full.f32 %r1263, %r1264, %r1178;
	// end inline asm
	mov.b32 	%f1541, %r1263;
	mov.b32 	%r1268, %f1505;
	mov.b32 	%r1267, %f776;
	// begin inline asm
	div.full.f32 %r1266, %r1267, %r1268;
	// end inline asm
	mov.b32 	%f1542, %r1266;
	mov.b32 	%r1270, %f777;
	// begin inline asm
	div.full.f32 %r1269, %r1270, %r1268;
	// end inline asm
	mov.b32 	%f1543, %r1269;
	mov.b32 	%r1274, %f1509;
	mov.b32 	%r1273, %f778;
	// begin inline asm
	div.full.f32 %r1272, %r1273, %r1274;
	// end inline asm
	mov.b32 	%f1544, %r1272;
	mov.b32 	%r1276, %f779;
	// begin inline asm
	div.full.f32 %r1275, %r1276, %r1274;
	// end inline asm
	mov.b32 	%f1545, %r1275;
	mov.b32 	%r1279, %f784;
	// begin inline asm
	div.full.f32 %r1278, %r1279, %r1268;
	// end inline asm
	mov.b32 	%f1546, %r1278;
	mov.b32 	%r1282, %f785;
	// begin inline asm
	div.full.f32 %r1281, %r1282, %r1268;
	// end inline asm
	mov.b32 	%f1547, %r1281;
	mov.b32 	%r1285, %f786;
	// begin inline asm
	div.full.f32 %r1284, %r1285, %r1274;
	// end inline asm
	mov.b32 	%f1548, %r1284;
	mov.b32 	%r1288, %f787;
	// begin inline asm
	div.full.f32 %r1287, %r1288, %r1274;
	// end inline asm
	mov.b32 	%f1549, %r1287;
	mov.b32 	%r1291, %f792;
	// begin inline asm
	div.full.f32 %r1290, %r1291, %r1268;
	// end inline asm
	mov.b32 	%f1550, %r1290;
	mov.b32 	%r1294, %f793;
	// begin inline asm
	div.full.f32 %r1293, %r1294, %r1268;
	// end inline asm
	mov.b32 	%f1551, %r1293;
	mov.b32 	%r1297, %f794;
	// begin inline asm
	div.full.f32 %r1296, %r1297, %r1274;
	// end inline asm
	mov.b32 	%f1552, %r1296;
	mov.b32 	%r1300, %f795;
	// begin inline asm
	div.full.f32 %r1299, %r1300, %r1274;
	// end inline asm
	mov.b32 	%f1553, %r1299;
	mov.b32 	%r1303, %f800;
	// begin inline asm
	div.full.f32 %r1302, %r1303, %r1268;
	// end inline asm
	mov.b32 	%f1554, %r1302;
	mov.b32 	%r1306, %f801;
	// begin inline asm
	div.full.f32 %r1305, %r1306, %r1268;
	// end inline asm
	mov.b32 	%f1555, %r1305;
	mov.b32 	%r1309, %f802;
	// begin inline asm
	div.full.f32 %r1308, %r1309, %r1274;
	// end inline asm
	mov.b32 	%f1556, %r1308;
	mov.b32 	%r1312, %f803;
	// begin inline asm
	div.full.f32 %r1311, %r1312, %r1274;
	// end inline asm
	mov.b32 	%f1557, %r1311;
	mov.b32 	%r1315, %f808;
	// begin inline asm
	div.full.f32 %r1314, %r1315, %r1268;
	// end inline asm
	mov.b32 	%f1558, %r1314;
	mov.b32 	%r1318, %f809;
	// begin inline asm
	div.full.f32 %r1317, %r1318, %r1268;
	// end inline asm
	mov.b32 	%f1559, %r1317;
	mov.b32 	%r1321, %f810;
	// begin inline asm
	div.full.f32 %r1320, %r1321, %r1274;
	// end inline asm
	mov.b32 	%f1560, %r1320;
	mov.b32 	%r1324, %f811;
	// begin inline asm
	div.full.f32 %r1323, %r1324, %r1274;
	// end inline asm
	mov.b32 	%f1561, %r1323;
	mov.b32 	%r1327, %f816;
	// begin inline asm
	div.full.f32 %r1326, %r1327, %r1268;
	// end inline asm
	mov.b32 	%f1562, %r1326;
	mov.b32 	%r1330, %f817;
	// begin inline asm
	div.full.f32 %r1329, %r1330, %r1268;
	// end inline asm
	mov.b32 	%f1563, %r1329;
	mov.b32 	%r1333, %f818;
	// begin inline asm
	div.full.f32 %r1332, %r1333, %r1274;
	// end inline asm
	mov.b32 	%f1564, %r1332;
	mov.b32 	%r1336, %f819;
	// begin inline asm
	div.full.f32 %r1335, %r1336, %r1274;
	// end inline asm
	mov.b32 	%f1565, %r1335;
	mov.b32 	%r1339, %f824;
	// begin inline asm
	div.full.f32 %r1338, %r1339, %r1268;
	// end inline asm
	mov.b32 	%f1566, %r1338;
	mov.b32 	%r1342, %f825;
	// begin inline asm
	div.full.f32 %r1341, %r1342, %r1268;
	// end inline asm
	mov.b32 	%f1567, %r1341;
	mov.b32 	%r1345, %f826;
	// begin inline asm
	div.full.f32 %r1344, %r1345, %r1274;
	// end inline asm
	mov.b32 	%f1568, %r1344;
	mov.b32 	%r1348, %f827;
	// begin inline asm
	div.full.f32 %r1347, %r1348, %r1274;
	// end inline asm
	mov.b32 	%f1569, %r1347;
	mov.b32 	%r1351, %f832;
	// begin inline asm
	div.full.f32 %r1350, %r1351, %r1268;
	// end inline asm
	mov.b32 	%f1570, %r1350;
	mov.b32 	%r1354, %f833;
	// begin inline asm
	div.full.f32 %r1353, %r1354, %r1268;
	// end inline asm
	mov.b32 	%f1571, %r1353;
	mov.b32 	%r1357, %f834;
	// begin inline asm
	div.full.f32 %r1356, %r1357, %r1274;
	// end inline asm
	mov.b32 	%f1572, %r1356;
	mov.b32 	%r1360, %f835;
	// begin inline asm
	div.full.f32 %r1359, %r1360, %r1274;
	// end inline asm
	mov.b32 	%f1573, %r1359;
	.loc	1 27 20
	shl.b32 	%r1446, %r1429, 6;
	.loc	1 103 48
	or.b32  	%r1447, %r1446, 512;
	or.b32  	%r1448, %r1446, 1024;
	or.b32  	%r1449, %r1446, 1536;
	or.b32  	%r1450, %r1446, 2048;
	or.b32  	%r1451, %r1446, 2560;
	or.b32  	%r1452, %r1446, 3072;
	or.b32  	%r1453, %r1446, 3584;
	or.b32  	%r1454, %r1446, 4096;
	or.b32  	%r1455, %r1446, 4608;
	or.b32  	%r1456, %r1446, 5120;
	or.b32  	%r1457, %r1446, 5632;
	or.b32  	%r1458, %r1446, 6144;
	or.b32  	%r1459, %r1446, 6656;
	or.b32  	%r1460, %r1446, 7168;
	or.b32  	%r1461, %r1446, 7680;
	.loc	1 103 44
	or.b32  	%r1462, %r4, %r1427;
	.loc	1 103 63
	add.s32 	%r1463, %r1462, %r1446;
	add.s32 	%r1464, %r1462, %r1447;
	add.s32 	%r1465, %r1462, %r1448;
	add.s32 	%r1466, %r1462, %r1449;
	add.s32 	%r1467, %r1462, %r1450;
	add.s32 	%r1468, %r1462, %r1451;
	add.s32 	%r1469, %r1462, %r1452;
	add.s32 	%r1470, %r1462, %r1453;
	add.s32 	%r1471, %r1462, %r1454;
	add.s32 	%r1472, %r1462, %r1455;
	add.s32 	%r1473, %r1462, %r1456;
	add.s32 	%r1474, %r1462, %r1457;
	add.s32 	%r1475, %r1462, %r1458;
	add.s32 	%r1476, %r1462, %r1459;
	add.s32 	%r1477, %r1462, %r1460;
	add.s32 	%r1478, %r1462, %r1461;
	.loc	1 103 28
	mul.wide.s32 	%rd83, %r1463, 4;
	add.s64 	%rd67, %rd15, %rd83;
	mul.wide.s32 	%rd84, %r1464, 4;
	add.s64 	%rd68, %rd15, %rd84;
	mul.wide.s32 	%rd85, %r1465, 4;
	add.s64 	%rd69, %rd15, %rd85;
	mul.wide.s32 	%rd86, %r1466, 4;
	add.s64 	%rd70, %rd15, %rd86;
	mul.wide.s32 	%rd87, %r1467, 4;
	add.s64 	%rd71, %rd15, %rd87;
	mul.wide.s32 	%rd88, %r1468, 4;
	add.s64 	%rd72, %rd15, %rd88;
	mul.wide.s32 	%rd89, %r1469, 4;
	add.s64 	%rd73, %rd15, %rd89;
	mul.wide.s32 	%rd90, %r1470, 4;
	add.s64 	%rd74, %rd15, %rd90;
	mul.wide.s32 	%rd91, %r1471, 4;
	add.s64 	%rd75, %rd15, %rd91;
	mul.wide.s32 	%rd92, %r1472, 4;
	add.s64 	%rd76, %rd15, %rd92;
	mul.wide.s32 	%rd93, %r1473, 4;
	add.s64 	%rd77, %rd15, %rd93;
	mul.wide.s32 	%rd94, %r1474, 4;
	add.s64 	%rd78, %rd15, %rd94;
	mul.wide.s32 	%rd95, %r1475, 4;
	add.s64 	%rd79, %rd15, %rd95;
	mul.wide.s32 	%rd96, %r1476, 4;
	add.s64 	%rd80, %rd15, %rd96;
	mul.wide.s32 	%rd97, %r1477, 4;
	add.s64 	%rd81, %rd15, %rd97;
	mul.wide.s32 	%rd98, %r1478, 4;
	add.s64 	%rd82, %rd15, %rd98;
	.loc	1 103 81
	mul.lo.s32 	%r1479, %r13, 68;
	add.s32 	%r1480, %r1479, %r3;
	shl.b32 	%r1481, %r1480, 2;
	mov.u32 	%r1482, global_smem;
	add.s32 	%r1483, %r1482, %r1481;
	st.shared.v2.f32 	[%r1483], {%f1510, %f1511};
	st.shared.v2.f32 	[%r1483+2176], {%f1512, %f1513};
	st.shared.v2.f32 	[%r1483+32], {%f1514, %f1515};
	add.s32 	%r1484, %r1479, %r15;
	shl.b32 	%r1485, %r1484, 2;
	add.s32 	%r1486, %r1482, %r1485;
	st.shared.v2.f32 	[%r1486+2176], {%f1516, %f1517};
	st.shared.v2.f32 	[%r1483+64], {%f1518, %f1519};
	add.s32 	%r1487, %r1479, %r17;
	shl.b32 	%r1488, %r1487, 2;
	add.s32 	%r1489, %r1482, %r1488;
	st.shared.v2.f32 	[%r1489+2176], {%f1520, %f1521};
	st.shared.v2.f32 	[%r1483+96], {%f1522, %f1523};
	add.s32 	%r1490, %r1479, %r19;
	shl.b32 	%r1491, %r1490, 2;
	add.s32 	%r1492, %r1482, %r1491;
	st.shared.v2.f32 	[%r1492+2176], {%f1524, %f1525};
	st.shared.v2.f32 	[%r1483+128], {%f1526, %f1527};
	st.shared.v2.f32 	[%r1483+2304], {%f1528, %f1529};
	st.shared.v2.f32 	[%r1483+160], {%f1530, %f1531};
	st.shared.v2.f32 	[%r1483+2336], {%f1532, %f1533};
	st.shared.v2.f32 	[%r1483+192], {%f1534, %f1535};
	st.shared.v2.f32 	[%r1483+2368], {%f1536, %f1537};
	st.shared.v2.f32 	[%r1483+224], {%f1538, %f1539};
	st.shared.v2.f32 	[%r1483+2400], {%f1540, %f1541};
	bar.sync 	0;
	add.s32 	%r1493, %r21, %r1427;
	shl.b32 	%r1494, %r1493, 2;
	add.s32 	%r1495, %r1482, %r1494;
	ld.shared.v4.u32 	{%r1362, %r1363, %r1364, %r1365}, [%r1495];
	ld.shared.v4.u32 	{%r1366, %r1367, %r1368, %r1369}, [%r1495+2176];
	ld.shared.v4.u32 	{%r1370, %r1371, %r1372, %r1373}, [%r1495+4352];
	ld.shared.v4.u32 	{%r1374, %r1375, %r1376, %r1377}, [%r1495+6528];
	ld.shared.v4.u32 	{%r1378, %r1379, %r1380, %r1381}, [%r1495+8704];
	ld.shared.v4.u32 	{%r1382, %r1383, %r1384, %r1385}, [%r1495+10880];
	ld.shared.v4.u32 	{%r1386, %r1387, %r1388, %r1389}, [%r1495+13056];
	ld.shared.v4.u32 	{%r1390, %r1391, %r1392, %r1393}, [%r1495+15232];
	bar.sync 	0;
	st.shared.v2.f32 	[%r1483], {%f1542, %f1543};
	st.shared.v2.f32 	[%r1483+2176], {%f1544, %f1545};
	st.shared.v2.f32 	[%r1483+32], {%f1546, %f1547};
	st.shared.v2.f32 	[%r1486+2176], {%f1548, %f1549};
	st.shared.v2.f32 	[%r1483+64], {%f1550, %f1551};
	st.shared.v2.f32 	[%r1489+2176], {%f1552, %f1553};
	st.shared.v2.f32 	[%r1483+96], {%f1554, %f1555};
	st.shared.v2.f32 	[%r1492+2176], {%f1556, %f1557};
	st.shared.v2.f32 	[%r1483+128], {%f1558, %f1559};
	st.shared.v2.f32 	[%r1483+2304], {%f1560, %f1561};
	st.shared.v2.f32 	[%r1483+160], {%f1562, %f1563};
	st.shared.v2.f32 	[%r1483+2336], {%f1564, %f1565};
	st.shared.v2.f32 	[%r1483+192], {%f1566, %f1567};
	st.shared.v2.f32 	[%r1483+2368], {%f1568, %f1569};
	st.shared.v2.f32 	[%r1483+224], {%f1570, %f1571};
	st.shared.v2.f32 	[%r1483+2400], {%f1572, %f1573};
	bar.sync 	0;
	ld.shared.v4.u32 	{%r1394, %r1395, %r1396, %r1397}, [%r1495];
	ld.shared.v4.u32 	{%r1398, %r1399, %r1400, %r1401}, [%r1495+2176];
	ld.shared.v4.u32 	{%r1402, %r1403, %r1404, %r1405}, [%r1495+4352];
	ld.shared.v4.u32 	{%r1406, %r1407, %r1408, %r1409}, [%r1495+6528];
	ld.shared.v4.u32 	{%r1410, %r1411, %r1412, %r1413}, [%r1495+8704];
	ld.shared.v4.u32 	{%r1414, %r1415, %r1416, %r1417}, [%r1495+10880];
	ld.shared.v4.u32 	{%r1418, %r1419, %r1420, %r1421}, [%r1495+13056];
	ld.shared.v4.u32 	{%r1422, %r1423, %r1424, %r1425}, [%r1495+15232];
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd67 + 0 ], { %r1362, %r1363, %r1364, %r1365 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd68 + 0 ], { %r1366, %r1367, %r1368, %r1369 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd69 + 0 ], { %r1370, %r1371, %r1372, %r1373 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd70 + 0 ], { %r1374, %r1375, %r1376, %r1377 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd71 + 0 ], { %r1378, %r1379, %r1380, %r1381 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd72 + 0 ], { %r1382, %r1383, %r1384, %r1385 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd73 + 0 ], { %r1386, %r1387, %r1388, %r1389 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd74 + 0 ], { %r1390, %r1391, %r1392, %r1393 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd75 + 0 ], { %r1394, %r1395, %r1396, %r1397 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd76 + 0 ], { %r1398, %r1399, %r1400, %r1401 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd77 + 0 ], { %r1402, %r1403, %r1404, %r1405 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd78 + 0 ], { %r1406, %r1407, %r1408, %r1409 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd79 + 0 ], { %r1410, %r1411, %r1412, %r1413 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd80 + 0 ], { %r1414, %r1415, %r1416, %r1417 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd81 + 0 ], { %r1418, %r1419, %r1420, %r1421 };
	// end inline asm
	// begin inline asm
	@%p131 st.global.v4.b32 [ %rd82 + 0 ], { %r1422, %r1423, %r1424, %r1425 };
	// end inline asm
	.loc	1 103 4
	ret;
$L__tmp8:
$L__func_end0:

}
	.file	1 "/work/06112/byou/ls6/torchinductor_cache/wh/cwhym3olocjmgmxp2aiwrvswsmljq3ahbxjufmfqgyc6aodf63db.py"
	.file	2 "/work/06112/byou/shared/miniforge3/envs/torch-2.5/lib/python3.12/site-packages/torch/_inductor/runtime/triton_helpers.py"
	.file	3 "/work/06112/byou/shared/miniforge3/envs/torch-2.5/lib/python3.12/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 1
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 2
.b8 46
.b8 0
.b8 3
.b8 8
.b8 32
.b8 11
.b8 0
.b8 0
.b8 3
.b8 46
.b8 1
.b8 17
.b8 1
.b8 18
.b8 1
.b8 49
.b8 19
.b8 0
.b8 0
.b8 4
.b8 29
.b8 0
.b8 49
.b8 19
.b8 17
.b8 1
.b8 18
.b8 1
.b8 88
.b8 11
.b8 89
.b8 11
.b8 87
.b8 11
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 242
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 99
.b8 119
.b8 104
.b8 121
.b8 109
.b8 51
.b8 111
.b8 108
.b8 111
.b8 99
.b8 106
.b8 109
.b8 103
.b8 109
.b8 120
.b8 112
.b8 50
.b8 97
.b8 105
.b8 119
.b8 114
.b8 118
.b8 115
.b8 119
.b8 115
.b8 109
.b8 108
.b8 106
.b8 113
.b8 51
.b8 97
.b8 104
.b8 98
.b8 120
.b8 106
.b8 117
.b8 102
.b8 109
.b8 102
.b8 113
.b8 103
.b8 121
.b8 99
.b8 54
.b8 97
.b8 111
.b8 100
.b8 102
.b8 54
.b8 51
.b8 100
.b8 98
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 47
.b8 119
.b8 111
.b8 114
.b8 107
.b8 47
.b8 48
.b8 54
.b8 49
.b8 49
.b8 50
.b8 47
.b8 98
.b8 121
.b8 111
.b8 117
.b8 47
.b8 108
.b8 115
.b8 54
.b8 47
.b8 116
.b8 111
.b8 114
.b8 99
.b8 104
.b8 105
.b8 110
.b8 100
.b8 117
.b8 99
.b8 116
.b8 111
.b8 114
.b8 95
.b8 99
.b8 97
.b8 99
.b8 104
.b8 101
.b8 47
.b8 119
.b8 104
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
.b8 2
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 95
.b8 0
.b8 1
.b8 3
.b64 $L__func_begin0
.b64 $L__func_end0
.b32 141
.b8 4
.b32 141
.b64 $L__tmp1
.b64 $L__tmp4
.b8 1
.b8 71
.b8 43
.b8 4
.b32 141
.b64 $L__tmp2
.b64 $L__tmp5
.b8 1
.b8 72
.b8 46
.b8 4
.b32 141
.b64 $L__tmp6
.b64 $L__tmp7
.b8 1
.b8 101
.b8 27
.b8 0
.b8 0
	}
	.section	.debug_loc	{	}
